{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regression Model 2.1 (RFR2.1)\n",
    "Without reservoir dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import geemap\n",
    "import ee\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "from random import randint\n",
    "import json\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import KFold, ShuffleSplit, RepeatedKFold, train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import ElasticNetCV, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import tensorflow as tf\n",
    "import HydroErr as he\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_dir = Path(\"../../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils = str(proj_dir / 'utils')\n",
    "sys.path.insert(0, utils)\n",
    "from sql import connect # utility functions for connecting to MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a connection object to the MySQL database\n",
    "# conn = connect.Connect(str(proj_dir / \"Methods/2.Data/DBManagement/mysql_config.ini\"))\n",
    "conn = connect.Connect(str(proj_dir / \".env/mysql_config.ini\"))\n",
    "connection = conn.conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reaches_and_dams = pd.read_csv(proj_dir / \"Methods/3.WaterTempEst/reaches_and_dams.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reaches_of_interest = [\"Columbia_River_59\",\"Willamette_River_15\", \"Kootenay_River_47\", \"Okanogan_River_29\"]\n",
    "# also test for Willamette_River_16, Kootenay_River_47, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = f\"\"\"\n",
    "# SELECT \n",
    "#     STR_TO_DATE(CONCAT(Year,\n",
    "#                     '-',\n",
    "#                     LPAD(Month, 2, '00'),\n",
    "#                     '-',\n",
    "#                     LPAD(DayOfMonth, 2, '00')),\n",
    "#             '%Y-%m-%d') AS Date,\n",
    "#     Month,\n",
    "#     DayOfMonth,\n",
    "#     ROUND(WaterTemp, 2) as WaterTemp,\n",
    "#     ROUND(LandTemp, 2) as LandTemp,\n",
    "#     ROUND(NDVI, 2) as NDVI,\n",
    "#     ClimateClass,\n",
    "#     --     ROUND(((watertemp - WaterTemperature) / WaterTemperature),\n",
    "#     --             2) AS PercentDeviation,\n",
    "#     --     ROUND((watertemp - WaterTemperature), 2) AS Deviation,\n",
    "#     Width,\n",
    "#     ReachID,\n",
    "#     ReachName,\n",
    "#     ROUND(InsituTemp, 2) AS InsituTemp\n",
    "# FROM\n",
    "#     (SELECT \n",
    "#         IF(DAY(ReachLandsatWaterTemp.date) < 15, 1, 15) AS DayOfMonth,\n",
    "#             MONTH(ReachLandsatWaterTemp.date) AS Month,\n",
    "#             YEAR(ReachLandsatWaterTemp.date) AS Year,\n",
    "#             AVG(ReachLandsatWaterTemp.Value) AS WaterTemp,\n",
    "#             AVG(ReachLandsatLandTemp.Value) AS LandTemp,\n",
    "#             AVG(ReachNDVI.Value) AS NDVI,\n",
    "#             IFNULL(Reaches.WidthMean, 30) AS Width,\n",
    "#             Reaches.ClimateClass AS ClimateClass,\n",
    "#             ReachLandsatWaterTemp.ReachID AS ReachID,\n",
    "#             Reaches.Name AS ReachName\n",
    "#     FROM\n",
    "#         ReachLandsatWaterTemp\n",
    "#     INNER JOIN ReachLandsatLandTemp USING (date , ReachID)\n",
    "#     INNER JOIN ReachNDVI USING (date , ReachID)\n",
    "#     INNER JOIN Reaches USING (ReachID)\n",
    "#     -- WHERE\n",
    "#     --    Reaches.Name NOT IN {tuple(reaches_of_interest)}\n",
    "#     --        AND ReachLandsatWaterTemp.Value > 0\n",
    "#     GROUP BY DayOfMonth , Month , Year , ClimateClass , ReachID , Width) AS T\n",
    "#     --         INNER JOIN\n",
    "#     --     ReachLandsatLTMSemiMonthly USING (DayOfMonth , Month , ReachID)\n",
    "#         LEFT JOIN\n",
    "#     (SELECT \n",
    "#         IF(DAY(ReachInsituWaterTemp.date) < 15, 1, 15) AS DayOfMonth,\n",
    "#             MONTH(ReachInsituWaterTemp.date) AS Month,\n",
    "#             YEAR(ReachInsituWaterTemp.date) AS Year,\n",
    "#             AVG(ReachInsituWaterTemp.Value) AS InsituTemp,\n",
    "#             ReachInsituWaterTemp.ReachID AS ReachID\n",
    "#     FROM\n",
    "#         ReachInsituWaterTemp\n",
    "#     INNER JOIN Reaches USING (ReachID)\n",
    "#     WHERE\n",
    "#         ReachInsituWaterTemp.Value > 0\n",
    "#     GROUP BY DayOfMonth , Month , Year , ReachID) AS I USING (DayOfMonth , Month , Year , ReachID)\n",
    "# -- ORDER BY RAND();\n",
    "# \"\"\" \n",
    "# # print(query)\n",
    "\n",
    "# df = conn.query_with_fetchmany(query, chunksize=100)\n",
    "\n",
    "# df.to_csv(proj_dir / \"Methods/2.Data/ML_input_data.csv\", index=False)\n",
    "\n",
    "df = pd.read_csv(proj_dir / \"Methods/2.Data/ML_input_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.concat([chunk for chunk in data], ignore_index=True)\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['DayOfYear'] = df['Date'].dt.dayofyear\n",
    "\n",
    "dels = pd.read_csv(proj_dir / \"Methods/3.WaterTempEst/rat_dels.csv\")\n",
    "dels[\"Date\"] = pd.to_datetime(dels[\"Date\"])\n",
    "sarea = pd.read_csv(proj_dir / \"Methods/3.WaterTempEst/rat_sarea.csv\")\n",
    "sarea[\"Date\"] = pd.to_datetime(sarea[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(reaches_and_dams, on=\"ReachName\", how=\"left\")\n",
    "df = df.merge(dels, on=[\"GranD_ID\", \"Date\"], how=\"left\")\n",
    "df = df.merge(sarea, on=[\"GranD_ID\", \"Date\"], how=\"left\")\n",
    "\n",
    "df.rename(columns={\"dS (m3)\": \"dels\", \"area (km2)\": \"sarea\", \"Within_n*10km\": \"rel_dist\"}, inplace=True)\n",
    "\n",
    "original_cols = df.columns\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot kde of dels\n",
    "# df[abs(df[\"dels\"])>0][\"dels\"].plot.kde()\n",
    "# df[\"sarea\"].plot.kde()\n",
    "# df[\"sarea_scaled\"].plot.kde()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scalers\n",
    "# load scalers and model\n",
    "with open(proj_dir / f\"Results/2.WaterTempEst/scalers.pkl\", \"rb\") as f:\n",
    "    scalers = pickle.load(f)\n",
    "\n",
    "    dayofmonth_scaler = scalers[\"dayofmonth_scaler\"]\n",
    "    month_scaler = scalers[\"month_scaler\"]\n",
    "    watertemp_scaler =  scalers[\"watertemp_scaler\"]\n",
    "    landtemp_scaler = scalers[\"landtemp_scaler\"]\n",
    "    width_scaler = scalers[\"width_scaler\"]\n",
    "    NDVI_scaler = scalers[\"NDVI_scaler\"]\n",
    "    climate_scaler = scalers[\"climate_scaler\"]\n",
    "    dels_scaler =   scalers[\"dels_scaler\"]\n",
    "    sarea_scaler = scalers[\"sarea_scaler\"]\n",
    "    rel_dist_scaler = scalers[\"rel_dist_scaler\"]\n",
    "\n",
    "# # define scalers\n",
    "# dayofmonth_scaler = MinMaxScaler(feature_range=(0, 1)).fit(pd.DataFrame({'DayOfMonth': range(1, 15+1)}))\n",
    "# month_scaler = MinMaxScaler(feature_range=(0, 1)).fit(pd.DataFrame({'Month': range(1, 12+1)}))\n",
    "# watertemp_scaler = StandardScaler().fit(df[['WaterTemp']])\n",
    "# landtemp_scaler = StandardScaler().fit(df[['LandTemp']])\n",
    "# # watertemp_scaler = MinMaxScaler(feature_range=(0, 1)).fit(df3[['WaterTemp']])\n",
    "# # landtemp_scaler = MinMaxScaler(feature_range=(0, 1)).fit(df3[['LandTemp']])\n",
    "# width_scaler = MinMaxScaler(feature_range=(0, 1)).fit(df[['Width']])\n",
    "# NDVI_scaler = StandardScaler().fit(df[['NDVI']])\n",
    "# # NDVI_scaler = MinMaxScaler(feature_range=(-1, 1)).fit(df3[['NDVI']])\n",
    "# climate_scaler = MinMaxScaler(feature_range=(0, 1)).fit(pd.DataFrame({'ClimateClass': range(1, 30+1)}))\n",
    "# dels_scaler = MinMaxScaler(feature_range=(0, 1)).fit(df[['dels']])\n",
    "# sarea_scaler = MinMaxScaler(feature_range=(0, 1)).fit(df[['sarea']])\n",
    "# rel_dist_scaler = MinMaxScaler(feature_range=(0, 1)).fit(pd.DataFrame({'rel_dist': range(0, 5+1)}))\n",
    "\n",
    "# replace missing values for dels, sarea, and rel_dist with the 0\n",
    "df[\"dels\"].fillna(0, inplace=True)\n",
    "df[\"sarea\"].fillna(0, inplace=True)\n",
    "df[\"rel_dist\"].fillna(0, inplace=True)\n",
    "\n",
    "# Scale values\n",
    "df[\"DayOfMonth_scaled\"] = dayofmonth_scaler.transform(df[[\"DayOfMonth\"]])\n",
    "df[\"Month_scaled\"] = month_scaler.transform(df[[\"Month\"]])\n",
    "df[\"LandTemp_scaled\"] = landtemp_scaler.transform(df[[\"LandTemp\"]])\n",
    "df[\"WaterTemp_scaled\"] = watertemp_scaler.transform(df[[\"WaterTemp\"]])\n",
    "df[\"Width_scaled\"] = width_scaler.transform(df[[\"Width\"]])\n",
    "df[\"NDVI_scaled\"] = NDVI_scaler.transform(df[[\"NDVI\"]])\n",
    "df[\"ClimateClass_scaled\"] = climate_scaler.transform(df[[\"ClimateClass\"]])\n",
    "df[\"dels_scaled\"] = dels_scaler.transform(df[[\"dels\"]])\n",
    "df[\"sarea_scaled\"] = sarea_scaler.transform(df[[\"sarea\"]])\n",
    "df[\"rel_dist_scaled\"] = rel_dist_scaler.transform(df[[\"rel_dist\"]])\n",
    "\n",
    "# # save the scalers\n",
    "# with open(proj_dir / f\"Results/2.WaterTempEst/scalers.pkl\", \"wb\") as f:\n",
    "#     pickle.dump({\n",
    "#         \"dayofmonth_scaler\": dayofmonth_scaler,\n",
    "#         \"month_scaler\": month_scaler,\n",
    "#         \"watertemp_scaler\": watertemp_scaler,\n",
    "#         \"landtemp_scaler\": landtemp_scaler,\n",
    "#         \"width_scaler\": width_scaler,\n",
    "#         \"NDVI_scaler\": NDVI_scaler,\n",
    "#         \"climate_scaler\": climate_scaler,\n",
    "#         \"dels_scaler\": dels_scaler,\n",
    "#         \"sarea_scaler\": sarea_scaler,\n",
    "#         \"rel_dist_scaler\": rel_dist_scaler,\n",
    "#     }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handpicked = df[\n",
    "    (df[\"ReachName\"].isin(reaches_of_interest))\n",
    "    & (df[\"InsituTemp\"].notnull())\n",
    "    & (df[\"rel_dist\"] != 0)\n",
    "].copy()\n",
    "\n",
    "# X and y to be used for model (excluding handpicked reaches of interest)\n",
    "X = df[\n",
    "    (~df[\"ReachName\"].isin(reaches_of_interest))\n",
    "    & (df[\"InsituTemp\"].notnull())\n",
    "    & (df[\"rel_dist\"] != 0)\n",
    "][\n",
    "    [\n",
    "        \"DayOfMonth_scaled\",\n",
    "        \"Month_scaled\",\n",
    "        \"LandTemp_scaled\",\n",
    "        \"Width_scaled\",\n",
    "        \"NDVI_scaled\",\n",
    "        \"ClimateClass_scaled\",\n",
    "        \"dels_scaled\",\n",
    "        \"sarea_scaled\",\n",
    "        \"rel_dist_scaled\",\n",
    "    ]\n",
    "]\n",
    "y = df[\n",
    "    (~df[\"ReachName\"].isin(reaches_of_interest))\n",
    "    & (df[\"InsituTemp\"].notnull())\n",
    "    & (df[\"rel_dist\"] != 0)\n",
    "][\"InsituTemp\"]\n",
    "X_rel_dist = df[\n",
    "    (~df[\"ReachName\"].isin(reaches_of_interest))\n",
    "    & (df[\"InsituTemp\"].notnull())\n",
    "    & (df[\"rel_dist\"] != 0)\n",
    "][\n",
    "    [\n",
    "        \"rel_dist\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "# dev set and test set (including handpicked reaches of interest)\n",
    "dev_set, test_set = train_test_split(\n",
    "    df[\n",
    "        (~df[\"ReachName\"].isin(reaches_of_interest))\n",
    "        & (df[\"InsituTemp\"].notnull())\n",
    "        & (df[\"rel_dist\"] != 0)\n",
    "    ],\n",
    "    test_size=0.1,\n",
    "    random_state=1993,\n",
    ")\n",
    "test_set = pd.concat([test_set, handpicked])\n",
    "\n",
    "X_dev = dev_set[\n",
    "    [\n",
    "        \"DayOfMonth_scaled\",\n",
    "        \"Month_scaled\",\n",
    "        \"LandTemp_scaled\",\n",
    "        \"Width_scaled\",\n",
    "        \"NDVI_scaled\",\n",
    "        \"ClimateClass_scaled\",\n",
    "        \"dels_scaled\",\n",
    "        \"sarea_scaled\",\n",
    "        \"rel_dist_scaled\",\n",
    "    ]\n",
    "]\n",
    "y_dev = dev_set[\"InsituTemp\"]\n",
    "\n",
    "X_test = test_set[\n",
    "    [\n",
    "        \"DayOfMonth_scaled\",\n",
    "        \"Month_scaled\",\n",
    "        \"LandTemp_scaled\",\n",
    "        \"Width_scaled\",\n",
    "        \"NDVI_scaled\",\n",
    "        \"ClimateClass_scaled\",\n",
    "        \"dels_scaled\",\n",
    "        \"sarea_scaled\",\n",
    "        \"rel_dist_scaled\",\n",
    "    ]\n",
    "]\n",
    "y_test = test_set[\"InsituTemp\"]\n",
    "\n",
    "# X and y for handpicked reaches of interest\n",
    "X_handpicked = handpicked[\n",
    "    [\n",
    "        \"DayOfMonth_scaled\",\n",
    "        \"Month_scaled\",\n",
    "        \"LandTemp_scaled\",\n",
    "        \"Width_scaled\",\n",
    "        \"NDVI_scaled\",\n",
    "        \"ClimateClass_scaled\",\n",
    "        \"dels_scaled\",\n",
    "        \"sarea_scaled\",\n",
    "        \"rel_dist_scaled\",\n",
    "    ]\n",
    "]\n",
    "y_handpicked = handpicked[\"InsituTemp\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"RFR2_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_splitter = RepeatedKFold(n_splits=5, n_repeats=10, random_state=1993)\n",
    "param_space = {\n",
    "    \"n_estimators\": [10, 20, 30, 40, 50, 75, 100, 125, 150, 175, 200, 250, 300, 350, 400, 450, 500, 1000],\n",
    "    # \"n_estimators\": [10, 11],\n",
    "    # \"max_depth\": [None],\n",
    "    # \"min_samples_split\": [2, 5],\n",
    "    # \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    # \"random_state\": [1993],\n",
    "}\n",
    "\n",
    "model = RandomForestRegressor(random_state=1993)\n",
    "search = GridSearchCV(model, param_space, cv=cv_splitter, scoring=\"neg_mean_squared_error\")\n",
    "search.fit(X, y)\n",
    "# model.fit(X, y)\n",
    "# print(model.alpha_)\n",
    "# print(model.intercept_)\n",
    "# print(LR1.predict([[0, 0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_n_estimators = search.cv_results_[\"param_n_estimators\"].tolist()\n",
    "mean_test_score = (-search.cv_results_[\"mean_test_score\"]).tolist()\n",
    "\n",
    "cv_results = pd.DataFrame(\n",
    "    {\n",
    "        \"param_n_estimators\": param_n_estimators,\n",
    "        \"mean_test_score\": mean_test_score,\n",
    "    }\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# ax.scatter(param_n_estimators, mean_test_score)\n",
    "ax.plot(param_n_estimators, mean_test_score, marker=\"o\")\n",
    "ax.set_xlabel(\"n_estimators\")\n",
    "ax.set_ylabel(\"mean_test_score\")\n",
    "ax.set_title(\"GridSearchCV Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results[\"delta\"] = round(cv_results[\"mean_test_score\"].diff(), 3)\n",
    "cv_results.to_csv(proj_dir / f\"Results/2.WaterTempEst/2.RandomForestRegression/{model_name}_cv_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dev_mse = pd.DataFrame(columns=list(search.cv_results_[\"params\"][0].keys()) + [\"mse\", \"fold\"])\n",
    "\n",
    "n_folds = search.n_splits_\n",
    "n_param_combinations = len(search.cv_results_[\"params\"])\n",
    "\n",
    "\n",
    "for j in range(n_param_combinations):\n",
    "    for i in range(n_folds):\n",
    "        model_dev_mse = pd.concat(\n",
    "            [\n",
    "                model_dev_mse,\n",
    "                pd.DataFrame(\n",
    "                    [\n",
    "                        {\n",
    "                            **search.cv_results_[\"params\"][j],\n",
    "                            \"mse\": search.cv_results_[\"split\" + str(i) + \"_test_score\"][j],\n",
    "                            \"fold\": i,\n",
    "                        }\n",
    "                    ]\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "model_dev_mse[\"mse\"] = -model_dev_mse[\"mse\"]\n",
    "model_dev_mse.to_csv(proj_dir / f\"Results/2.WaterTempEst/2.RandomForestRegression/{model_name}_dev_mse.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually choose the best set of hyperparameters based on the plot\n",
    "selected_n_estimators = 250\n",
    "# selected_combination = search.best_params_\n",
    "selected_combination = search.cv_results_[\"params\"][param_n_estimators.index(selected_n_estimators)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the hyperparameters\n",
    "hyperparameters = pd.DataFrame(\n",
    "    {\n",
    "        \"hyperparameter\": list(selected_combination.keys()),\n",
    "        \"value\": list(selected_combination.values()),\n",
    "    }\n",
    ")\n",
    "hyperparameters.model = model_name\n",
    "\n",
    "hyperparameters.to_csv(proj_dir / f\"Results/2.WaterTempEst/2.RandomForestRegression/{model_name}_hyperparameters.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation (Using cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"model\",\n",
    "        \"fold\",\n",
    "        \"rmse\",\n",
    "        \"nse\",\n",
    "        \"mse\",\n",
    "        \"r_sqaured\",\n",
    "        \"rmse_within_50\",\n",
    "        \"nse_within_50\",\n",
    "        \"r_sqaured_within_50\",\n",
    "        \"mse_within_50\",\n",
    "        \"rmse_beyond_50\",\n",
    "        \"nse_beyond_50\",\n",
    "        \"r_sqaured_beyond_50\",\n",
    "        \"mse_beyond_50\",\n",
    "    ]\n",
    ")\n",
    "# model_final = search.best_estimator_\n",
    "# model_final = RandomForestRegressor(**selected_combination, random_state=1993)\n",
    "model_final = RandomForestRegressor(n_estimators=250, random_state=1993)\n",
    "\n",
    "cv_splitter = RepeatedKFold(n_splits=5, n_repeats=10, random_state=1993)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(cv_splitter.split(X)):\n",
    "    X_train_, X_test_ = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train_, y_test_ = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    X_test_within_50 = X.iloc[test_index][X_rel_dist.iloc[test_index][\"rel_dist\"] != 0]\n",
    "    y_test_within_50 = y.iloc[test_index][X_rel_dist.iloc[test_index][\"rel_dist\"] != 0]\n",
    "\n",
    "    X_test_beyond_50 = X.iloc[test_index][X_rel_dist.iloc[test_index][\"rel_dist\"] == 0]\n",
    "    y_test_beyond_50 = y.iloc[test_index][X_rel_dist.iloc[test_index][\"rel_dist\"] == 0]\n",
    "\n",
    "    model_final.fit(X_train_, y_train_)\n",
    "    y_pred = model_final.predict(X_test_)\n",
    "    y_pred_within_50 = model_final.predict(X_test_within_50)\n",
    "    # y_pred_beyond_50 = model_final.predict(X_test_beyond_50)\n",
    "\n",
    "    rmse = he.rmse(simulated_array=list(y_pred.squeeze()), observed_array=list(y_test_))\n",
    "    nse = he.nse(simulated_array=list(y_pred.squeeze()), observed_array=list(y_test_))\n",
    "    r_squared = he.r_squared(\n",
    "        simulated_array=list(y_pred.squeeze()), observed_array=list(y_test_)\n",
    "    )\n",
    "    mse = he.mse(simulated_array=list(y_pred.squeeze()), observed_array=list(y_test_))\n",
    "\n",
    "    rmse_within_50 = he.rmse(\n",
    "        simulated_array=list(y_pred_within_50.squeeze()),\n",
    "        observed_array=list(y_test_within_50),\n",
    "    )\n",
    "    nse_within_50 = he.nse(\n",
    "        simulated_array=list(y_pred_within_50.squeeze()),\n",
    "        observed_array=list(y_test_within_50),\n",
    "    )\n",
    "    r_squared_within_50 = he.r_squared(\n",
    "        simulated_array=list(y_pred_within_50.squeeze()),\n",
    "        observed_array=list(y_test_within_50),\n",
    "    )\n",
    "    mse_within_50 = he.mse(\n",
    "        simulated_array=list(y_pred_within_50.squeeze()),\n",
    "        observed_array=list(y_test_within_50),\n",
    "    )\n",
    "\n",
    "    rmse_beyond_50 = None\n",
    "    nse_beyond_50 = None\n",
    "    r_squared_beyond_50 = None\n",
    "    mse_beyond_50 = None\n",
    "\n",
    "    model_eval = pd.concat(\n",
    "        [\n",
    "            model_eval,\n",
    "            pd.DataFrame(\n",
    "                [\n",
    "                    [\n",
    "                        f\"{model_name}\",\n",
    "                        i,\n",
    "                        rmse,\n",
    "                        nse,\n",
    "                        r_squared,\n",
    "                        mse,\n",
    "                        rmse_within_50,\n",
    "                        nse_within_50,\n",
    "                        r_squared_within_50,\n",
    "                        mse_within_50,\n",
    "                        rmse_beyond_50,\n",
    "                        nse_beyond_50,\n",
    "                        r_squared_beyond_50,\n",
    "                        mse_beyond_50,\n",
    "                    ]\n",
    "                ],\n",
    "                columns=[\n",
    "                    \"model\",\n",
    "                    \"fold\",\n",
    "                    \"rmse\",\n",
    "                    \"nse\",\n",
    "                    \"r_sqaured\",\n",
    "                    \"mse\",\n",
    "                    \"rmse_within_50\",\n",
    "                    \"nse_within_50\",\n",
    "                    \"r_sqaured_within_50\",\n",
    "                    \"mse_within_50\",\n",
    "                    \"rmse_beyond_50\",\n",
    "                    \"nse_beyond_50\",\n",
    "                    \"r_sqaured_beyond_50\",\n",
    "                    \"mse_beyond_50\",\n",
    "                ],\n",
    "            ),\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final = RandomForestRegressor(n_estimators=250, random_state=1993)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot of model evaluation metrics\n",
    "fig, ax = plt.subplots()\n",
    "model_eval.boxplot(\n",
    "    column=[\n",
    "        \"rmse\",\n",
    "        \"rmse_within_50\",\n",
    "        # \"rmse_beyond_50\",\n",
    "    ],\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_ylabel(\"RMSE\")\n",
    "ax.set_title(\"Boxplot of RMSE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval.to_csv(proj_dir / f\"Results/2.WaterTempEst/2.RandomForestRegression/{model_name}_eval.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing (Train with dev set and test with test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.fit(X_dev, y_dev)\n",
    "y_pred = model_final.predict(X_test)\n",
    "rmse = he.rmse(simulated_array=list(y_pred), observed_array=list(y_test))\n",
    "nse = he.nse(simulated_array=list(y_pred), observed_array=list(y_test))\n",
    "r_squared = he.r_squared(simulated_array=list(y_pred), observed_array=list(y_test))\n",
    "mse = he.mse(simulated_array=list(y_pred), observed_array=list(y_test))\n",
    "\n",
    "model_test = pd.DataFrame([[f\"{model_name}\", rmse, nse, r_squared, mse]], columns=[\"model\", \"rmse\", \"nse\", \"r_sqaured\", \"mse\"])\n",
    "model_test.to_csv(proj_dir / f\"Results/2.WaterTempEst/2.RandomForestRegression/{model_name}_test.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set[f\"{model_name}\"] = y_pred\n",
    "test_set.to_csv(proj_dir / f\"Results/2.WaterTempEst/2.RandomForestRegression/{model_name}_test_set.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the test model vs. insitu\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(test_set[\"InsituTemp\"], test_set[f\"{model_name}\"])\n",
    "ax.set_xlabel(\"InsituTemp\")\n",
    "ax.set_ylabel(f\"{model_name}\")\n",
    "ax.set_title(f\"{model_name} vs. InsituTemp\")\n",
    "\n",
    "# add 1:1 line\n",
    "lims = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "]\n",
    "ax.plot(lims, lims, \"k-\", alpha=0.75, zorder=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally, train the model with the complete dataset and store it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X and y to be used for final model (excluding handpicked reaches of interest)\n",
    "X_final = df[\n",
    "    (~df[\"ReachName\"].isin(reaches_of_interest)) & (df[\"InsituTemp\"].notnull())\n",
    "][\n",
    "    [\n",
    "        \"DayOfMonth_scaled\",\n",
    "        \"Month_scaled\",\n",
    "        \"LandTemp_scaled\",\n",
    "        \"Width_scaled\",\n",
    "        \"NDVI_scaled\",\n",
    "        \"ClimateClass_scaled\",\n",
    "        \"dels_scaled\",\n",
    "        \"sarea_scaled\",\n",
    "        \"rel_dist_scaled\",\n",
    "    ]\n",
    "]\n",
    "y_final = df[\n",
    "    (~df[\"ReachName\"].isin(reaches_of_interest)) & (df[\"InsituTemp\"].notnull())\n",
    "][\"InsituTemp\"]\n",
    "\n",
    "model_final.fit(X_final, y_final)\n",
    "\n",
    "# # save the coefficients\n",
    "# coefficients = pd.DataFrame(\n",
    "#     {\n",
    "#         \"variable\": X_final.columns.to_list() + [\"intercept\"],\n",
    "#         \"coefficient\": model_final.coef_.tolist() + [model_final.intercept_],\n",
    "#     }\n",
    "# )\n",
    "# coefficients[\"model\"] = model_name\n",
    "\n",
    "# coefficients.to_csv(proj_dir / f\"Results/2.WaterTempEst/2.RandomForestRegression/{model_name}_coefficients.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "with open(proj_dir / f\"Results/2.WaterTempEst/2.RandomForestRegression/{model_name}_final_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model_final, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydrothermal-history",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
