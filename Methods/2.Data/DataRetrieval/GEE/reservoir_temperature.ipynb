{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import geemap\n",
    "import ee\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "from random import randint\n",
    "import json\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_dir = Path(\"../../../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils = str(proj_dir / 'utils')\n",
    "sys.path.insert(0, utils)\n",
    "from sql import connect # utility functions for connecting to MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reservoirs_shp = Path(proj_dir, \"Data/GIS/shapefiles/gee_basin_params/basin_reservoirs.shp\")\n",
    "\n",
    "# Data/GIS/shapefiles/CRBReservoirs.shp\n",
    "temperature_gauges_shp = Path(proj_dir, \"Data/GIS/shapefiles/temperature_gauges.geojson\")\n",
    "\n",
    "data_dir = Path(proj_dir, \"Data/LandsatTemperature\")\n",
    "os.makedirs(data_dir/'reservoirs', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to MySQL database...\n",
      "Connection established.\n"
     ]
    }
   ],
   "source": [
    "# Create a connection object to the MySQL database\n",
    "# conn = connect.Connect(str(proj_dir / \"Methods/2.Data/DBManagement/mysql_config.ini\"))\n",
    "conn = connect.Connect(str(proj_dir / \".env/mysql_config.ini\"))\n",
    "connection = conn.conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map = geemap.Map()\n",
    "# Map\n",
    "# ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reservoirs = geemap.shp_to_ee(reservoirs_shp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reservoir = reservoirs.filter(ee.Filter.eq(\"DAM_NAME\", \"Dworshak Dam\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the timeframe for the temperature data\n",
    "# L9startDate = '2021-10-01'\n",
    "# L8startDate = '2013-03-01'\n",
    "# L9endDate = '2023-05-31'\n",
    "# L8endDate = '2023-05-31'\n",
    "L9startDate = \"2023-11-01\"\n",
    "L8startDate = \"2023-11-01\"\n",
    "L9endDate = \"2023-12-31\"\n",
    "L8endDate = \"2023-12-31\"\n",
    "\n",
    "# startDate = L9startDate\n",
    "# endDate = L9endDate\n",
    "\n",
    "startDate = None # None for default or date in string format \"YYYY-MM-DD\"\n",
    "endDate = datetime.datetime.today()\n",
    "if startDate is None:\n",
    "    startDate = endDate - datetime.timedelta(days=90)\n",
    "else:\n",
    "    startDate = datetime.datetime.strptime(startDate, \"%Y-%m-%d\")\n",
    "\n",
    "# format dates as strings\n",
    "startDate = startDate.strftime(\"%Y-%m-%d\")\n",
    "endDate = endDate.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# ndwi threshold\n",
    "ndwi_threshold = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-06 2024-01-04\n"
     ]
    }
   ],
   "source": [
    "print(startDate, endDate)\n",
    "# import datetime\n",
    "\n",
    "# endDate = datetime.datetime.today()\n",
    "# startDate = endDate - datetime.timedelta(days=90)\n",
    "# print(startDate.strftime(\"%Y-%m-%d\"), endDate.strftime(\"%Y-%m-%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divideDates(startDate, endDate):\n",
    "    \"\"\"\n",
    "    Divide the timeframe into years\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    startDate: str\n",
    "        start date\n",
    "    endDate: str\n",
    "        end date\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        list of tuples of start and end dates\n",
    "    \"\"\"\n",
    "\n",
    "    # convert start and end dates to datetime objects\n",
    "    startDate_ = datetime.datetime.strptime(startDate, \"%Y-%m-%d\")\n",
    "    endDate_ = datetime.datetime.strptime(endDate, \"%Y-%m-%d\")\n",
    "\n",
    "    # get years from start and end dates\n",
    "    # startYear = pd.to_datetime(startDate).year\n",
    "    # endYear = pd.to_datetime(endDate).year\n",
    "    startYear = startDate_.year\n",
    "    endYear = endDate_.year\n",
    "\n",
    "    # divide the timeframe into years\n",
    "    dates = []\n",
    "    for year in range(startYear, endYear+1):\n",
    "        if year == startYear and year == endYear:\n",
    "            dates.append([startDate, endDate])\n",
    "        elif year == startYear:\n",
    "            dates.append([startDate, f\"{year}-12-31\"])\n",
    "        elif year == endYear:\n",
    "            # if the difference end date and start of the year is less than 30 days, then replace the end date of the previous append with the end date\n",
    "            # the purpose of this is to avoid having a date range of less than 30 days (especially at the beginning of the last year)\n",
    "            if (endDate_ - datetime.datetime(year, 1, 1)).days < 45:\n",
    "                dates[-1][1] = endDate\n",
    "            else:\n",
    "                dates.append([f\"{year}-01-01\", endDate])\n",
    "        else:\n",
    "            dates.append([f\"{year}-01-01\", f\"{year}-12-31\"])\n",
    "\n",
    "    return dates\n",
    "\n",
    "def prepL8(image):\n",
    "    \"\"\"\n",
    "    Prepare Landsat 8 image for analysis\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    image: ee.Image\n",
    "        Landsat 8 image\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    ee.Image\n",
    "        prepared Landsat 8 image\n",
    "    \"\"\"\n",
    "\n",
    "    # develop masks for unwanted pixels (fill, cloud, shadow)\n",
    "    qa_mask = image.select(\"QA_PIXEL\").bitwiseAnd(int(\"11111\", 2)).eq(0)\n",
    "    saturation_mask = image.select(\"QA_RADSAT\").eq(0)\n",
    "\n",
    "    # apply scaling factors to the appropriate bands\n",
    "    def getFactorImage(factorNames):\n",
    "        factorList = image.toDictionary().select(factorNames).values()\n",
    "        return ee.Image.constant(factorList)\n",
    "\n",
    "    scaleImg = getFactorImage([\"REFLECTANCE_MULT_BAND_.|TEMPERATURE_MULT_BAND_ST_B10\"])\n",
    "    offsetImg = getFactorImage([\"REFLECTANCE_ADD_BAND_.|TEMPERATURE_ADD_BAND_ST_B10\"])\n",
    "    scaled = image.select(\"SR_B.|ST_B10\").multiply(scaleImg).add(offsetImg)\n",
    "\n",
    "    # replace original bands with scaled bands and apply masks\n",
    "    return (\n",
    "        image.addBands(scaled, overwrite=True)\n",
    "        .updateMask(qa_mask)\n",
    "        .updateMask(saturation_mask)\n",
    "    )\n",
    "\n",
    "def addNDWI(image):\n",
    "    \"\"\"\n",
    "    Add NDWI band to image\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    image: ee.Image\n",
    "        Landsat 8 image\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    ee.Image\n",
    "        Landsat 8 image with NDWI band\n",
    "    \"\"\"\n",
    "\n",
    "    ndwi = image.expression(\n",
    "        \"NDWI = (green - NIR)/(green + NIR)\",\n",
    "        {\"green\": image.select(\"SR_B3\"), \"NIR\": image.select(\"SR_B5\")},\n",
    "    ).rename(\"NDWI\")\n",
    "\n",
    "    return image.addBands(ndwi)\n",
    "\n",
    "def addCelcius(image):\n",
    "    \"\"\"\n",
    "    Add Celcius band to image\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    image: ee.Image\n",
    "        Landsat 8 image\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    ee.Image\n",
    "        Landsat 8 image with Celcius band\n",
    "    \"\"\"\n",
    "    celcius = image.select(\"ST_B10\").subtract(273.15).rename(\"Celcius\")\n",
    "\n",
    "    return image.addBands(celcius)\n",
    "\n",
    "def extractTempSeries(\n",
    "    reservoir,\n",
    "    startDate,\n",
    "    endDate,\n",
    "    ndwi_threshold=0.2,\n",
    "    imageCollection=\"LANDSAT/LC08/C02/T1_L2\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Extract temperature time series for a reservoir\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    reservoir: ee.Feature\n",
    "        reservoir\n",
    "    startDate: str\n",
    "        start date\n",
    "    endDate: str\n",
    "        end date\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    ee.ImageCollection\n",
    "        temperature time series\n",
    "    \"\"\"\n",
    "\n",
    "    L8 = (\n",
    "        ee.ImageCollection(imageCollection)\n",
    "        .filterDate(startDate, endDate)\n",
    "        .filterBounds(reservoir)\n",
    "    )\n",
    "\n",
    "    def extractTemp(date):\n",
    "        date = ee.Date(date)\n",
    "        # prepare Landsat 8 image and add the NDWI band, and Celcius band\n",
    "        processedL8 = (\n",
    "            L8.filterDate(date, date.advance(1, \"day\"))\n",
    "            .map(prepL8)\n",
    "            .map(addCelcius)\n",
    "            .map(addNDWI)\n",
    "        )\n",
    "\n",
    "        # get quality NDWI and use it as the water mask\n",
    "        ndwi = processedL8.qualityMosaic(\"NDWI\").select(\"NDWI\")\n",
    "        waterMaskNdwi = ndwi.gte(ndwi_threshold)\n",
    "        # nonWaterMask = ndwi.lt(ndwi_threshold)\n",
    "\n",
    "        mosaic = processedL8.mosaic()\n",
    "        waterMask = mosaic.select(\"QA_PIXEL\").bitwiseAnd(int(\"10000000\", 2)).neq(0)\n",
    "        nonWaterMask = mosaic.select(\"QA_PIXEL\").bitwiseAnd(int(\"10000000\", 2)).eq(0)\n",
    "\n",
    "        # find the mean of the images in the collection\n",
    "        meanL8 = (\n",
    "            processedL8.reduce(ee.Reducer.mean()).addBands(ndwi, [\"NDWI\"], True).updateMask(waterMask).set(\"system:time_start\", date)\n",
    "        )\n",
    "\n",
    "        # get the mean temperature of the reservoir\n",
    "        temp = meanL8.select([\"Celcius_mean\"]).reduceRegion(\n",
    "            reducer=ee.Reducer.mean(), geometry=reservoir.geometry(), scale=30\n",
    "        )\n",
    "\n",
    "        return ee.Feature(None, {\"date\": date.format(\"YYYY-MM-dd\"), \"temp(C)\": temp})\n",
    "\n",
    "    dates = ee.List(L8.map(\n",
    "        lambda image: ee.Feature(None, {\"date\": image.date().format(\"YYYY-MM-dd\")})\n",
    "    ).distinct(\"date\").aggregate_array(\"date\").getInfo())\n",
    "\n",
    "    tempSeries = ee.FeatureCollection(dates.map(extractTemp))\n",
    "\n",
    "    return tempSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee_dam_names = reservoirs.select(\"DAM_NAME\", retainGeometry=False).getInfo()\n",
    "ee_uniq_ids = reservoirs.select(\"uniq_id\", retainGeometry=False).getInfo()\n",
    "dam_names = [i[\"properties\"][\"DAM_NAME\"] for i in ee_dam_names[\"features\"]]\n",
    "uniq_ids = [i[\"properties\"][\"uniq_id\"] for i in ee_uniq_ids[\"features\"]]\n",
    "\n",
    "# uniq_ids = uniq_ids[7:]\n",
    "# dam_names = dam_names[7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runExtraction(data_dir, checkpoint_path=None, connection=None):\n",
    "    if checkpoint_path is None:\n",
    "        checkpoint = {\"reservoir_index\": 0}\n",
    "    else:\n",
    "        with open(checkpoint_path, \"r\") as f:\n",
    "            checkpoint = json.load(f)\n",
    "\n",
    "    uniq_ids_ = uniq_ids[checkpoint[\"reservoir_index\"]:]\n",
    "    dam_names_ = dam_names[checkpoint[\"reservoir_index\"]:]\n",
    "\n",
    "    for dam_name, uniq_id in zip(dam_names_, uniq_ids_):\n",
    "        \n",
    "        tempSeriesList = []\n",
    "\n",
    "        # check if file exists\n",
    "        if os.path.isfile(data_dir / \"reservoirs\" / f\"{uniq_id}.csv\"):\n",
    "            existing_df = pd.read_csv(data_dir / \"reservoirs\" / f\"{uniq_id}.csv\")\n",
    "            existing_df[\"date\"] = pd.to_datetime(existing_df[\"date\"])\n",
    "            tempSeriesList.append(existing_df)\n",
    "            # print(\"File exists!\")\n",
    "\n",
    "        # for landsat8\n",
    "        dates = divideDates(startDate, endDate)\n",
    "        # dates = divideDates(L8startDate, L8endDate)\n",
    "        for date in dates:\n",
    "            startDate_ = date[0]\n",
    "            endDate_ = date[1]\n",
    "\n",
    "            reservoir = reservoirs.filter(ee.Filter.eq(\"DAM_NAME\", ee.String(dam_name)))\n",
    "            tempSeries = extractTempSeries(reservoir, startDate_, endDate_, ndwi_threshold, imageCollection=\"LANDSAT/LC08/C02/T1_L2\")\n",
    "            tempSeries = geemap.ee_to_pandas(tempSeries)\n",
    "\n",
    "            # convert date column to datetime\n",
    "            tempSeries[\"date\"] = pd.to_datetime(tempSeries[\"date\"])\n",
    "            tempSeries[\"temp(C)\"] = (\n",
    "                tempSeries[\"temp(C)\"].apply(lambda x: x[\"Celcius_mean\"]).astype(float)\n",
    "            )\n",
    "\n",
    "            # append time series to list\n",
    "            tempSeriesList.append(tempSeries)\n",
    "\n",
    "        # for landsat9\n",
    "        # dates = divideDates(startDate, endDate)\n",
    "        # dates = divideDates(L9startDate, L9endDate)\n",
    "        for date in dates:\n",
    "            startDate_ = date[0]\n",
    "            endDate_ = date[1]\n",
    "\n",
    "            reservoir = reservoirs.filter(ee.Filter.eq(\"DAM_NAME\", ee.String(dam_name)))\n",
    "            tempSeries = extractTempSeries(reservoir, startDate_, endDate_, ndwi_threshold, imageCollection=\"LANDSAT/LC09/C02/T1_L2\")\n",
    "            tempSeries = geemap.ee_to_pandas(tempSeries)\n",
    "\n",
    "            # convert date column to datetime\n",
    "            tempSeries[\"date\"] = pd.to_datetime(tempSeries[\"date\"])\n",
    "            tempSeries[\"temp(C)\"] = (\n",
    "                tempSeries[\"temp(C)\"].apply(lambda x: x[\"Celcius_mean\"]).astype(float)\n",
    "            )\n",
    "\n",
    "            # append time series to list\n",
    "            tempSeriesList.append(tempSeries)\n",
    "\n",
    "        # concatenate all time series\n",
    "        tempSeries_df = pd.concat(tempSeriesList, ignore_index=True)\n",
    "\n",
    "        # sort by date\n",
    "        tempSeries_df.sort_values(by=\"date\", inplace=True)\n",
    "        # remove duplicates\n",
    "        tempSeries_df.drop_duplicates(subset=\"date\", inplace=True)\n",
    "\n",
    "        # # save time series to csv\n",
    "        # tempSeries_df.to_csv(data_dir / \"reservoirs\" / f\"{uniq_id}.csv\", index=False)\n",
    "\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        data = tempSeries_df.dropna().copy()\n",
    "        # convert the date column to datetime YYYY-MM-DD\n",
    "        data['date'] = pd.to_datetime(data['date'])\n",
    "        data['date'] = data['date'].dt.date\n",
    "\n",
    "        for i, row in data.iterrows():\n",
    "            query = f\"\"\"\n",
    "            INSERT INTO DamLandsatWaterTemp (Date, DamID, Value)\n",
    "            SELECT '{row['date']}', (SELECT DamID FROM Dams WHERE Name = \"{dam_name}\"), {row['temp(C)']}\n",
    "            WHERE NOT EXISTS (SELECT * FROM DamLandsatWaterTemp WHERE Date = '{row['date']}' AND DamID = (SELECT DamID FROM Dams WHERE Name = \"{dam_name}\"))\n",
    "            \"\"\"\n",
    "            try:\n",
    "                cursor.execute(query)\n",
    "                connection.commit()\n",
    "            except:\n",
    "                print(query)\n",
    "                raise Exception(\"Error!\")\n",
    "            \n",
    "        checkpoint[\"reservoir_index\"] += 1\n",
    "        json.dump(checkpoint, open(checkpoint_path, \"w\"))\n",
    "\n",
    "        print(f\"{dam_name} done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['2023-10-06', '2024-01-04']]\n",
      "Keechelus done!\n",
      "[['2023-10-06', '2024-01-04']]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(data_dir / \"reservoirs\" / \"checkpoint.json\", \"r\") as f:\n",
    "        checkpoint = json.load(f)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Creating new checkpoint...\")\n",
    "    checkpoint = {\"reservoir_index\": 0}\n",
    "    # save checkpoint\n",
    "    json.dump(checkpoint, open(data_dir / \"reservoirs\" / \"checkpoint.json\", \"w\"))\n",
    "\n",
    "repeated_tries = 0\n",
    "\n",
    "while checkpoint[\"reservoir_index\"] < len(dam_names):\n",
    "    try:\n",
    "        # extract temperature time series for each reservoir\n",
    "        runExtraction(data_dir, data_dir / \"reservoirs\" / \"checkpoint.json\", connection)\n",
    "        repeated_tries = 0 # reset repeated_tries\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "        # sleep for 0.5 - 3 minutes\n",
    "        s_time = randint(30, 120)\n",
    "        print(f\"Sleeping for {s_time} seconds...\")\n",
    "        time.sleep(s_time)\n",
    "        print(\"Restarting from checkpoint...\")  # restart from checkpoint\n",
    "\n",
    "        repeated_tries += 1\n",
    "\n",
    "        if repeated_tries > 3:\n",
    "            checkpoint[\"reservoir_index\"] += 1\n",
    "\n",
    "            repeated_tries = 0\n",
    "\n",
    "            json.dump(checkpoint, open(data_dir / \"reservoirs\" / \"checkpoint.json\", \"w\"))\n",
    "\n",
    "    finally:\n",
    "        # load checkpoint\n",
    "        with open(data_dir / \"reservoirs\" / \"checkpoint.json\", \"r\") as f:\n",
    "            checkpoint = json.load(f)\n",
    "\n",
    "if checkpoint[\"reservoir_index\"] >= len(dam_names):\n",
    "    checkpoint[\"reservoir_index\"] = 0\n",
    "    json.dump(checkpoint, open(data_dir / \"reservoirs\" / \"checkpoint.json\", \"w\"))\n",
    "\n",
    "print(\"All done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# # extract temperature time series for each reservoir\n",
    "# for dam_name, uniq_id in zip(dam_names, uniq_ids):\n",
    "\n",
    "#     tempSeriesList = []\n",
    "\n",
    "#     # check if file exists\n",
    "#     if os.path.isfile(data_dir / \"reservoirs\" / f\"{uniq_id}.csv\"):\n",
    "#         existing_df = pd.read_csv(data_dir / \"reservoirs\" / f\"{uniq_id}.csv\")\n",
    "#         existing_df[\"date\"] = pd.to_datetime(existing_df[\"date\"])\n",
    "#         tempSeriesList.append(existing_df)\n",
    "#         # print(\"File exists!\")\n",
    "\n",
    "#     # for landsat8\n",
    "#     # dates = divideDates(startDate, endDate)\n",
    "#     dates = divideDates(L8startDate, L8endDate)\n",
    "#     for date in dates:\n",
    "#         startDate_ = date[0]\n",
    "#         endDate_ = date[1]\n",
    "\n",
    "#         reservoir = reservoirs.filter(ee.Filter.eq(\"DAM_NAME\", ee.String(dam_name)))\n",
    "#         tempSeries = extractTempSeries(reservoir, startDate_, endDate_, ndwi_threshold, imageCollection=\"LANDSAT/LC08/C02/T1_L2\")\n",
    "#         tempSeries = geemap.ee_to_pandas(tempSeries)\n",
    "\n",
    "#         # convert date column to datetime\n",
    "#         tempSeries[\"date\"] = pd.to_datetime(tempSeries[\"date\"])\n",
    "#         tempSeries[\"temp(C)\"] = (\n",
    "#             tempSeries[\"temp(C)\"].apply(lambda x: x[\"Celcius_mean\"]).astype(float)\n",
    "#         )\n",
    "\n",
    "#         # append time series to list\n",
    "#         tempSeriesList.append(tempSeries)\n",
    "\n",
    "#     # for landsat9\n",
    "#     # dates = divideDates(startDate, endDate)\n",
    "#     dates = divideDates(L9startDate, L9endDate)\n",
    "#     for date in dates:\n",
    "#         startDate_ = date[0]\n",
    "#         endDate_ = date[1]\n",
    "\n",
    "#         reservoir = reservoirs.filter(ee.Filter.eq(\"DAM_NAME\", ee.String(dam_name)))\n",
    "#         tempSeries = extractTempSeries(reservoir, startDate_, endDate_, ndwi_threshold, imageCollection=\"LANDSAT/LC09/C02/T1_L2\")\n",
    "#         tempSeries = geemap.ee_to_pandas(tempSeries)\n",
    "\n",
    "#         # convert date column to datetime\n",
    "#         tempSeries[\"date\"] = pd.to_datetime(tempSeries[\"date\"])\n",
    "#         tempSeries[\"temp(C)\"] = (\n",
    "#             tempSeries[\"temp(C)\"].apply(lambda x: x[\"Celcius_mean\"]).astype(float)\n",
    "#         )\n",
    "\n",
    "#         # append time series to list\n",
    "#         tempSeriesList.append(tempSeries)\n",
    "\n",
    "#     # concatenate all time series\n",
    "#     tempSeries_df = pd.concat(tempSeriesList, ignore_index=True)\n",
    "\n",
    "#     # sort by date\n",
    "#     tempSeries_df.sort_values(by=\"date\", inplace=True)\n",
    "#     # remove duplicates\n",
    "#     tempSeries_df.drop_duplicates(subset=\"date\", inplace=True)\n",
    "\n",
    "#     # # save time series to csv\n",
    "#     # tempSeries_df.to_csv(data_dir / \"reservoirs\" / f\"{uniq_id}.csv\", index=False)\n",
    "\n",
    "#     cursor = connection.cursor()\n",
    "\n",
    "#     data = tempSeries_df.dropna().copy()\n",
    "#     # convert the date column to datetime YYYY-MM-DD\n",
    "#     data['date'] = pd.to_datetime(data['date'])\n",
    "#     data['date'] = data['date'].dt.date\n",
    "\n",
    "#     for i, row in data.iterrows():\n",
    "#         query = f\"\"\"\n",
    "#         INSERT INTO DamLandsatWaterTemp (Date, DamID, Value)\n",
    "#         SELECT '{row['date']}', (SELECT DamID FROM Dams WHERE Name = \"{dam_name}\"), {row['temp(C)']}\n",
    "#         WHERE NOT EXISTS (SELECT * FROM DamLandsatWaterTemp WHERE Date = '{row['date']}' AND DamID = (SELECT DamID FROM Dams WHERE Name = \"{dam_name}\"))\n",
    "#         \"\"\"\n",
    "#         try:\n",
    "#             cursor.execute(query)\n",
    "#             connection.commit()\n",
    "#         except:\n",
    "#             print(query)\n",
    "#             raise Exception(\"Error!\")\n",
    "        \n",
    "#         # print(i, dam_name, row[\"date\"], row[\"temp(C)\"])\n",
    "\n",
    "#         # cursor.execute(query)\n",
    "#         # connection.commit()\n",
    "\n",
    "\n",
    "#     print(dam_name, \"Done!\")\n",
    "#     s_time = randint(60, 120)\n",
    "#     # print(f\"Sleeping for {s_time} seconds...\")\n",
    "#     time.sleep(s_time)\n",
    "#     # print(\"Restarting from checkpoint...\")  # restart from checkpoint\n",
    "# print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydrothermal-history",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
