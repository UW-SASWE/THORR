{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geemap\n",
    "import ee\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "from random import randint\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "river_shp = Path(\"/Users/gdarkwah/Library/CloudStorage/OneDrive-UW/01-Research/01-Hydrothermal History/Data/GIS/shapefiles/MySQL_reaches/bufferedReaches.shp\")\n",
    "temperature_gauges_shp = Path(\"/Users/gdarkwah/Library/CloudStorage/OneDrive-UW/01-Research/01-Hydrothermal History/Data/GIS/shapefiles/temperature_gauges.geojson\")\n",
    "\n",
    "data_dir = Path(\"/Users/gdarkwah/Library/CloudStorage/OneDrive-UW/01-Research/01-Hydrothermal History/Data/temp_timeseries/Landsat8\")\n",
    "# data_dir = Path(\"/Users/gdarkwah/eeDownloads\")\n",
    "os.makedirs(data_dir/'reaches', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(river_shp)\n",
    "gdf = gdf.to_crs(epsg=4326)\n",
    "# save shapefile\n",
    "# gdf.to_file(data_dir/'rivers'/'rivers.shp')\n",
    "# gdf[gdf[\"GNIS_Name\"]==\"Columbia River\"].to_file(data_dir/'rivers'/'rivers.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map = geemap.Map()\n",
    "# Map\n",
    "# ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reservoirs = geemap.shp_to_ee(data_dir/'rivers'/'rivers.shp')\n",
    "# Map.addLayer(reservoirs, {}, \"Reservoirs\")\n",
    "# Map.centerObject(reservoirs, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the timeframe for the temperature data\n",
    "# L9startDate = '2021-10-01'\n",
    "# L8startDate = '2013-03-01'\n",
    "# L9endDate = '2023-05-31'\n",
    "# L8endDate = '2023-05-31'\n",
    "L9startDate = '2023-05-31'\n",
    "L8startDate = '2023-05-31'\n",
    "L9endDate = '2023-07-31'\n",
    "L8endDate = '2023-07-31'\n",
    "\n",
    "# ndwi threshold\n",
    "ndwi_threshold = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divideDates(startDate, endDate):\n",
    "    \"\"\"\n",
    "    Divide the timeframe into years\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    startDate: str\n",
    "        start date\n",
    "    endDate: str\n",
    "        end date\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        list of tuples of start and end dates\n",
    "    \"\"\"\n",
    "\n",
    "    startYear = pd.to_datetime(startDate).year\n",
    "    endYear = pd.to_datetime(endDate).year\n",
    "\n",
    "    dates = []\n",
    "    for year in range(startYear, endYear+1):\n",
    "        if year == startYear and year == endYear:\n",
    "            dates.append((startDate, endDate))\n",
    "        elif year == startYear:\n",
    "            dates.append((startDate, f\"{year}-12-31\"))\n",
    "        elif year == endYear:\n",
    "            dates.append((f\"{year}-01-01\", endDate))\n",
    "        else:\n",
    "            dates.append((f\"{year}-01-01\", f\"{year}-12-31\"))\n",
    "\n",
    "    return dates\n",
    "\n",
    "def prepL8(image):\n",
    "    \"\"\"\n",
    "    Prepare Landsat 8 image for analysis\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    image: ee.Image\n",
    "        Landsat 8 image\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    ee.Image\n",
    "        prepared Landsat 8 image\n",
    "    \"\"\"\n",
    "\n",
    "    # develop masks for unwanted pixels (fill, cloud, shadow)\n",
    "    qa_mask = image.select(\"QA_PIXEL\").bitwiseAnd(int(\"11111\", 2)).eq(0)\n",
    "    saturation_mask = image.select(\"QA_RADSAT\").eq(0)\n",
    "\n",
    "    # apply scaling factors to the appropriate bands\n",
    "    def getFactorImage(factorNames):\n",
    "        factorList = image.toDictionary().select(factorNames).values()\n",
    "        return ee.Image.constant(factorList)\n",
    "\n",
    "    scaleImg = getFactorImage([\"REFLECTANCE_MULT_BAND_.|TEMPERATURE_MULT_BAND_ST_B10\"])\n",
    "    offsetImg = getFactorImage([\"REFLECTANCE_ADD_BAND_.|TEMPERATURE_ADD_BAND_ST_B10\"])\n",
    "    scaled = image.select(\"SR_B.|ST_B10\").multiply(scaleImg).add(offsetImg)\n",
    "\n",
    "    # replace original bands with scaled bands and apply masks\n",
    "    return (\n",
    "        image.addBands(scaled, overwrite=True)\n",
    "        .updateMask(qa_mask)\n",
    "        .updateMask(saturation_mask)\n",
    "    )\n",
    "\n",
    "def addNDWI(image):\n",
    "    \"\"\"\n",
    "    Add NDWI band to image\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    image: ee.Image\n",
    "        Landsat 8 image\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    ee.Image\n",
    "        Landsat 8 image with NDWI band\n",
    "    \"\"\"\n",
    "\n",
    "    ndwi = image.expression(\n",
    "        \"NDWI = (green - NIR)/(green + NIR)\",\n",
    "        {\"green\": image.select(\"SR_B3\"), \"NIR\": image.select(\"SR_B5\")},\n",
    "    ).rename(\"NDWI\")\n",
    "\n",
    "    return image.addBands(ndwi)\n",
    "\n",
    "def addNDVI(image):\n",
    "    \"\"\"\n",
    "    Add NDVI band to image\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    image: ee.Image\n",
    "        Landsat 8 image\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    ee.Image\n",
    "        Landsat 8 image with NDVI band\n",
    "    \"\"\"\n",
    "\n",
    "    ndvi = image.expression(\n",
    "        \"NDVI = (NIR - red)/(NIR + red)\",\n",
    "        {\"red\": image.select(\"SR_B4\"), \"NIR\": image.select(\"SR_B5\")},\n",
    "    ).rename(\"NDVI\")\n",
    "\n",
    "    return image.addBands(ndvi)\n",
    "\n",
    "def addCelcius(image):\n",
    "    \"\"\"\n",
    "    Add Celcius band to image\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    image: ee.Image\n",
    "        Landsat 8 image\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    ee.Image\n",
    "        Landsat 8 image with Celcius band\n",
    "    \"\"\"\n",
    "    celcius = image.select(\"ST_B10\").subtract(273.15).rename(\"Celcius\")\n",
    "\n",
    "    return image.addBands(celcius)\n",
    "\n",
    "def extractTempSeries(\n",
    "    reservoir,\n",
    "    startDate,\n",
    "    endDate,\n",
    "    ndwi_threshold=0.2,\n",
    "    imageCollection=\"LANDSAT/LC09/C02/T1_L2\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Extract temperature time series for a reservoir\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    reservoir: ee.Feature\n",
    "        reservoir\n",
    "    startDate: str\n",
    "        start date\n",
    "    endDate: str\n",
    "        end date\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    ee.ImageCollection\n",
    "        temperature time series\n",
    "    \"\"\"\n",
    "\n",
    "    L8 = (\n",
    "        ee.ImageCollection(imageCollection)\n",
    "        .filterDate(startDate, endDate)\n",
    "        .filterBounds(reservoir)\n",
    "    )\n",
    "\n",
    "    # def extractWaterTemp(date):\n",
    "    def extractData(date):\n",
    "        date = ee.Date(date)\n",
    "        # prepare Landsat 8 image and add the NDWI band, and Celcius band\n",
    "        processedL8 = (\n",
    "            L8.filterDate(date, date.advance(1, \"day\"))\n",
    "            .map(prepL8)\n",
    "            .map(addCelcius)\n",
    "            .map(addNDWI)\n",
    "            .map(addNDVI)\n",
    "        )\n",
    "\n",
    "        # get quality NDWI and use it as the water mask\n",
    "        ndwi = processedL8.qualityMosaic(\"NDWI\").select(\"NDWI\")\n",
    "        waterMask = ndwi.gte(ndwi_threshold)\n",
    "        nonWaterMask = ndwi.lt(ndwi_threshold)\n",
    "\n",
    "        # find the mean of the images in the collection\n",
    "        meanL8water = (\n",
    "            processedL8.reduce(ee.Reducer.mean()).addBands(ndwi, [\"NDWI\"], True).updateMask(waterMask).set(\"system:time_start\", date)\n",
    "        )\n",
    "        meanL8nonwater = (\n",
    "            processedL8.reduce(ee.Reducer.mean()).addBands(ndwi, [\"NDWI\"], True).updateMask(nonWaterMask).set(\"system:time_start\", date)\n",
    "        )\n",
    "\n",
    "        # get the mean temperature of the reservoir\n",
    "        watertemp = meanL8water.select([\"Celcius_mean\"]).reduceRegion(\n",
    "            reducer=ee.Reducer.mean(), geometry=reservoir.geometry(), scale=30\n",
    "        )\n",
    "        landtemp = meanL8nonwater.select([\"Celcius_mean\"]).reduceRegion(\n",
    "            reducer=ee.Reducer.mean(), geometry=reservoir.geometry(), scale=30\n",
    "        )\n",
    "        ndvi = meanL8nonwater.select([\"NDVI_mean\"]).reduceRegion(\n",
    "            reducer=ee.Reducer.mean(), geometry=reservoir.geometry(), scale=30\n",
    "        )\n",
    "\n",
    "        return ee.Feature(None, {\"date\": date.format(\"YYYY-MM-dd\"), \"watertemp(C)\": watertemp, \"landtemp(C)\": landtemp, \"NDVI\": ndvi})\n",
    "\n",
    "    def extractLandTemp(date):\n",
    "        date = ee.Date(date)\n",
    "        # prepare Landsat 8 image and add the NDWI band, and Celcius band\n",
    "        processedL8 = (\n",
    "            L8.filterDate(date, date.advance(1, \"day\"))\n",
    "            .map(prepL8)\n",
    "            .map(addCelcius)\n",
    "            .map(addNDWI)\n",
    "        )\n",
    "\n",
    "        # get quality NDWI and use it as the water mask\n",
    "        ndwi = processedL8.qualityMosaic(\"NDWI\").select(\"NDWI\")\n",
    "        nonWaterMask = ndwi.lt(ndwi_threshold)\n",
    "\n",
    "        # find the mean of the images in the collection\n",
    "        meanL8 = (\n",
    "            processedL8.reduce(ee.Reducer.mean()).addBands(ndwi, [\"NDWI\"], True).updateMask(nonWaterMask).set(\"system:time_start\", date)\n",
    "        )\n",
    "\n",
    "        # get the mean temperature of the reservoir\n",
    "        temp = meanL8.select([\"Celcius_mean\"]).reduceRegion(\n",
    "            reducer=ee.Reducer.mean(), geometry=reservoir.geometry(), scale=30\n",
    "        )\n",
    "\n",
    "        return ee.Feature(None, {\"date\": date.format(\"YYYY-MM-dd\"), \"temp(C)\": temp})\n",
    "\n",
    "    dates = ee.List(L8.map(\n",
    "        lambda image: ee.Feature(None, {\"date\": image.date().format(\"YYYY-MM-dd\")})\n",
    "    ).distinct(\"date\").aggregate_array(\"date\"))\n",
    "\n",
    "    # waterTempSeries = ee.FeatureCollection(dates.map(extractWaterTemp))\n",
    "    # landTempSeries = ee.FeatureCollection(dates.map(extractLandTemp))\n",
    "\n",
    "    dataSeries = ee.FeatureCollection(dates.map(extractData))\n",
    "\n",
    "    # return waterTempSeries, landTempSeries\n",
    "    return dataSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ee_to_df(featureCollection):\n",
    "    \"\"\"\n",
    "    Convert an ee.FeatureCollection to a pandas.DataFrame\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    featureCollection: ee.FeatureCollection\n",
    "        feature collection\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    columns = featureCollection.first().propertyNames().getInfo()\n",
    "    rows = featureCollection.reduceColumns(\n",
    "        ee.Reducer.toList(len(columns)\n",
    "                          ), columns\n",
    "    ).values().get(0).getInfo()\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=columns)\n",
    "    df.drop(columns=[\"system:index\"], inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def download_ee_csv(downloadUrl):\n",
    "    \"\"\"\n",
    "    Download an ee.FeatureCollection as a csv file\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    downloadUrl: str\n",
    "        download url\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(downloadUrl)\n",
    "    df.drop(columns=[\"system:index\", \".geo\"], inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reachwiseExtraction(\n",
    "    reaches,\n",
    "    startDate,\n",
    "    endDate,\n",
    "    ndwi_threshold=0.2,\n",
    "    imageCollection=\"LANDSAT/LC09/C02/T1_L2\",\n",
    "    reach_ids=None,\n",
    "    checkpoint_path=None\n",
    "):\n",
    "    \n",
    "    if checkpoint_path is None:\n",
    "        checkpoint = {\"river_index\": 0, \"reach_index\": 0}\n",
    "    else:\n",
    "        with open(checkpoint_path, \"r\") as f:\n",
    "            checkpoint = json.load(f)\n",
    "\n",
    "    \n",
    "    if reach_ids is None:\n",
    "        ee_reach_ids = reaches.select(\"reach_id\", retainGeometry=False).getInfo()\n",
    "        reach_ids = [i[\"properties\"][\"reach_id\"] for i in ee_reach_ids[\"features\"]][checkpoint[\"reach_index\"]:]\n",
    "        # reach_ids = gdf[\"reach_id\"].tolist()\n",
    "\n",
    "    # extract temperature time series for each reservoir\n",
    "    for reach_id in reach_ids:\n",
    "        # print(f\"Reach {reach_id} started!\")\n",
    "        dates = divideDates(startDate, endDate)\n",
    "        waterTempSeriesList = []\n",
    "        landTempSeriesList = []\n",
    "\n",
    "        dataSeriesList = []\n",
    "\n",
    "        if os.path.isfile(data_dir / \"reaches\" / f\"{reach_id}_watertemp.csv\"):\n",
    "            existing_df = pd.read_csv(data_dir / \"reaches\" / f\"{reach_id}_watertemp.csv\")\n",
    "            existing_df[\"date\"] = pd.to_datetime(existing_df[\"date\"])\n",
    "            waterTempSeriesList.append(existing_df)\n",
    "            # print(\"File exists!\")\n",
    "\n",
    "        if os.path.isfile(\n",
    "            data_dir / \"reaches\" / f\"{reach_id}_landtemp.csv\"\n",
    "        ):\n",
    "            existing_df = pd.read_csv(\n",
    "                data_dir / \"reaches\" / f\"{reach_id}_landtemp.csv\"\n",
    "            )\n",
    "            existing_df[\"date\"] = pd.to_datetime(existing_df[\"date\"])\n",
    "            landTempSeriesList.append(existing_df)\n",
    "            # print(\"File exists!\")\n",
    "\n",
    "        if os.path.isfile(data_dir / \"reaches\" / f\"{reach_id}.csv\"):\n",
    "            existing_df = pd.read_csv(data_dir / \"reaches\" / f\"{reach_id}.csv\")\n",
    "            existing_df[\"date\"] = pd.to_datetime(existing_df[\"date\"])\n",
    "            dataSeriesList.append(existing_df)\n",
    "            # print(\"File exists!\")\n",
    "\n",
    "        for date in dates:\n",
    "            startDate_ = date[0]\n",
    "            endDate_ = date[1]\n",
    "\n",
    "            reservoir = reaches.filter(ee.Filter.eq(\"reach_id\", ee.String(reach_id)))\n",
    "            # waterTempSeries, landTempSeries= extractTempSeries(\n",
    "            #     reservoir, startDate_, endDate_, ndwi_threshold, imageCollection\n",
    "            # )\n",
    "            # waterTempSeries = geemap.ee_to_pandas(waterTempSeries)\n",
    "            # landTempSeries = geemap.ee_to_pandas(landTempSeries)\n",
    "            dataSeries = extractTempSeries(\n",
    "                reservoir, startDate_, endDate_, ndwi_threshold, imageCollection\n",
    "            )\n",
    "            dataSeries = geemap.ee_to_pandas(dataSeries)\n",
    "\n",
    "            # convert date column to datetime\n",
    "            # waterTempSeries[\"date\"] = pd.to_datetime(waterTempSeries[\"date\"])\n",
    "            # landTempSeries[\"date\"] = pd.to_datetime(landTempSeries[\"date\"])\n",
    "            dataSeries['date'] = pd.to_datetime(dataSeries['date'])\n",
    "\n",
    "            # waterTempSeries[\"temp(C)\"] = (\n",
    "            #     waterTempSeries[\"temp(C)\"]\n",
    "            #     .apply(lambda x: x[\"Celcius_mean\"])\n",
    "            #     .astype(float)\n",
    "            # )\n",
    "            # landTempSeries[\"temp(C)\"] = (\n",
    "            #     landTempSeries[\"temp(C)\"]\n",
    "            #     .apply(lambda x: x[\"Celcius_mean\"])\n",
    "            #     .astype(float)\n",
    "            # )\n",
    "\n",
    "            dataSeries[\"watertemp(C)\"] = (\n",
    "                dataSeries[\"watertemp(C)\"]\n",
    "                .apply(lambda x: x[\"Celcius_mean\"])\n",
    "                .astype(float)\n",
    "            )\n",
    "            dataSeries[\"landtemp(C)\"] = (\n",
    "                dataSeries[\"landtemp(C)\"]\n",
    "                .apply(lambda x: x[\"Celcius_mean\"])\n",
    "                .astype(float)\n",
    "            )\n",
    "            dataSeries[\"NDVI\"] = (\n",
    "                dataSeries[\"NDVI\"]\n",
    "                .apply(lambda x: x[\"NDVI_mean\"])\n",
    "                .astype(float)\n",
    "            )\n",
    "\n",
    "            # append time series to list\n",
    "            # waterTempSeriesList.append(waterTempSeries)\n",
    "            # landTempSeriesList.append(landTempSeries)\n",
    "            dataSeriesList.append(dataSeries)\n",
    "\n",
    "            s_time = randint(5, 15)\n",
    "            time.sleep(s_time)\n",
    "\n",
    "        # concatenate all time series\n",
    "        # waterTempSeries_df = pd.concat(waterTempSeriesList, ignore_index=True)\n",
    "        # landTempSeries_df = pd.concat(landTempSeriesList, ignore_index=True)\n",
    "        dataSeries_df = pd.concat(dataSeriesList, ignore_index=True)\n",
    "\n",
    "        # sort by date\n",
    "        # waterTempSeries_df.sort_values(by=\"date\", inplace=True)\n",
    "        # landTempSeries_df.sort_values(by=\"date\", inplace=True)\n",
    "        dataSeries_df.sort_values(by=\"date\", inplace=True)\n",
    "        # #drop null values\n",
    "        # # waterTempSeries_df.dropna(inplace=True)\n",
    "        # # landTempSeries_df.dropna(inplace=True)\n",
    "        # dataSeries_df.dropna(inplace=True)\n",
    "        # remove duplicates\n",
    "        # waterTempSeries_df.drop_duplicates(subset=\"date\", inplace=True)\n",
    "        # landTempSeries_df.drop_duplicates(subset=\"date\", inplace=True)\n",
    "        dataSeries_df.drop_duplicates(subset=\"date\", inplace=True)\n",
    "\n",
    "        # save time series to csv\n",
    "        # waterTempSeries_df.to_csv(\n",
    "        #     data_dir / \"reaches\" / f\"{reach_id}_watertemp.csv\", index=False\n",
    "        # )\n",
    "        # landTempSeries_df.to_csv(\n",
    "        #     data_dir / \"reaches\" / f\"{reach_id}_landtemp.csv\", index=False\n",
    "        # )\n",
    "        dataSeries_df.to_csv(\n",
    "            data_dir / \"reaches\" / f\"{reach_id}.csv\", index=False\n",
    "        )\n",
    "\n",
    "        checkpoint[\"reach_index\"] += 1\n",
    "        json.dump(checkpoint, open(checkpoint_path, \"w\"))\n",
    "        print(f\"Reach {reach_id} done!\")\n",
    "        # s_time = randint(30, 60)\n",
    "        # time.sleep(s_time)\n",
    "\n",
    "\n",
    "    # print(\"All done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(river_shp)\n",
    "gdf = gdf.to_crs(epsg=4326)\n",
    "\n",
    "rivers = gdf[\"GNIS_Name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runExtraction(data_dir, checkpoint_path=None):\n",
    "    if checkpoint_path is None:\n",
    "        checkpoint = {\"river_index\": 0, \"reach_index\": 0}\n",
    "    else:\n",
    "        with open(checkpoint_path, \"r\") as f:\n",
    "            checkpoint = json.load(f)\n",
    "    \n",
    "    # gdf = gpd.read_file(river_shp)\n",
    "    # gdf = gdf.to_crs(epsg=4326)\n",
    "    \n",
    "    # unique_rivers = gdf[\"GNIS_Name\"].unique()\n",
    "    # unique_rivers = gdf[\"GNIS_Name\"].unique()[checkpoint[\"river_index\"]:]\n",
    "    unique_rivers = rivers[checkpoint[\"river_index\"]:]\n",
    "    # unique_rivers = redo_rivers[checkpoint[\"river_index\"]:]\n",
    "    \n",
    "\n",
    "    for river in unique_rivers:\n",
    "        gdf[gdf[\"GNIS_Name\"]==river].to_file(data_dir/'reaches'/'rivers.shp')\n",
    "        reach_ids = gdf[gdf[\"GNIS_Name\"]==river][\"reach_id\"].tolist()\n",
    "        reach_ids = reach_ids[checkpoint[\"reach_index\"]:]\n",
    "\n",
    "        reaches = geemap.shp_to_ee(data_dir/'reaches'/'rivers.shp')\n",
    "\n",
    "        # Landsat8 Data\n",
    "        # reachwiseExtraction(reaches, L8startDate, L8endDate, ndwi_threshold, imageCollection=\"LANDSAT/LC08/C02/T1_L2\", reach_ids=reach_ids, checkpoint_path=checkpoint_path)\n",
    "        # Landsat9 Data\n",
    "        reachwiseExtraction(reaches, L9startDate, L9endDate, ndwi_threshold, imageCollection=\"LANDSAT/LC09/C02/T1_L2\", reach_ids=reach_ids, checkpoint_path=checkpoint_path)\n",
    "\n",
    "        checkpoint[\"reach_index\"] = 0\n",
    "        checkpoint[\"river_index\"] += 1\n",
    "        json.dump(checkpoint, open(checkpoint_path, \"w\"))\n",
    "\n",
    "        # s_time = randint(30,120)\n",
    "        # time.sleep(s_time)\n",
    "\n",
    "        print(f\"{river} done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf[\"GNIS_Name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(data_dir/\"reaches\"/\"checkpoint.json\", \"r\") as f:\n",
    "        checkpoint = json.load(f)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Creating new checkpoint...\")\n",
    "    checkpoint = {\"river_index\": 0, \"reach_index\": 0}\n",
    "    # save checkpoint\n",
    "    json.dump(checkpoint, open(data_dir/\"reaches\"/\"checkpoint.json\", \"w\"))\n",
    "\n",
    "repeated_tries = 0\n",
    "\n",
    "# while checkpoint[\"river_index\"] < len(gdf[\"GNIS_Name\"].unique()):\n",
    "while checkpoint[\"river_index\"] < len(rivers):\n",
    "# while checkpoint[\"river_index\"] < len(redo_rivers):\n",
    "    try:\n",
    "        runExtraction(data_dir, data_dir/\"reaches\"/\"checkpoint.json\")\n",
    "        repeated_tries = 0 # reset repeated_tries\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        # sleep for 0.5 - 3 minutes\n",
    "        s_time = randint(30,120)\n",
    "        print(f\"Sleeping for {s_time} seconds...\")\n",
    "        time.sleep(s_time)\n",
    "        print(\"Restarting from checkpoint...\") # restart from checkpoint\n",
    "\n",
    "        repeated_tries += 1 # increment repeated_tries\n",
    "\n",
    "        # if repeated_tries > 3, increment river_index and reset reach_index\n",
    "        if repeated_tries > 3:\n",
    "            checkpoint[\"reach_index\"] += 1\n",
    "            current_river = gdf[\"GNIS_Name\"].unique()[checkpoint[\"river_index\"]]\n",
    "            if checkpoint[\"reach_index\"] >= len(gdf[gdf[\"GNIS_Name\"]==current_river][\"reach_id\"].tolist()):\n",
    "                checkpoint[\"reach_index\"] = 0\n",
    "                checkpoint[\"river_index\"] += 1\n",
    "            repeated_tries = 0\n",
    "\n",
    "            # save checkpoint\n",
    "            json.dump(checkpoint, open(data_dir/\"reaches\"/\"checkpoint.json\", \"w\"))\n",
    "    finally:\n",
    "        # save checkpoint\n",
    "        with open(data_dir/\"reaches\"/\"checkpoint.json\", \"r\") as f:\n",
    "            checkpoint = json.load(f)\n",
    "\n",
    "# reset checkpoint if all rivers are done\n",
    "# if checkpoint[\"river_index\"] >= len(gdf[\"GNIS_Name\"].unique()):\n",
    "if checkpoint[\"river_index\"] >= len(rivers):\n",
    "    checkpoint[\"river_index\"] = 0\n",
    "    checkpoint[\"reach_index\"] = 0\n",
    "    json.dump(checkpoint, open(data_dir/\"reaches\"/\"checkpoint.json\", \"w\"))\n",
    "\n",
    "print(\"All done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydrothermal-history",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
