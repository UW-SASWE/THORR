{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import geemap\n",
    "import ee\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "from random import randint\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_dir = Path(\"../../../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils = str(proj_dir / 'utils')\n",
    "sys.path.insert(0, utils)\n",
    "from sql import connect # utility functions for connecting to MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "river_shp = Path(\n",
    "    proj_dir / \"Data/GIS/shapefiles/flowlines_to_reaches/bufferedReaches.shp\"\n",
    ")\n",
    "temperature_gauges_shp = Path(\n",
    "    proj_dir / \"Data/GIS/shapefiles/temperature_gauges.geojson\"\n",
    ")\n",
    "\n",
    "data_dir = Path(proj_dir, \"Data/LandsatTemperature\")\n",
    "# data_dir = Path(\"/Users/gdarkwah/eeDownloads\")\n",
    "os.makedirs(data_dir / \"reaches\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a connection object to the MySQL database\n",
    "# conn = connect.Connect(str(proj_dir / \"Methods/2.Data/DBManagement/mysql_config.ini\"))\n",
    "conn = connect.Connect(str(proj_dir / \".env/mysql_config.ini\"))\n",
    "connection = conn.conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(river_shp)\n",
    "gdf = gdf.to_crs(epsg=4326)\n",
    "# save shapefile\n",
    "# gdf.to_file(data_dir/'rivers'/'rivers.shp')\n",
    "# gdf[gdf[\"GNIS_Name\"]==\"Columbia River\"].to_file(data_dir/'rivers'/'rivers.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map = geemap.Map()\n",
    "# Map\n",
    "# ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reservoirs = geemap.shp_to_ee(data_dir/'rivers'/'rivers.shp')\n",
    "# Map.addLayer(reservoirs, {}, \"Reservoirs\")\n",
    "# Map.centerObject(reservoirs, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the timeframe for the temperature data\n",
    "# L9startDate = '2021-10-01'\n",
    "# L8startDate = '2013-03-01'\n",
    "L9startDate = '2023-09-01'\n",
    "L8startDate = '2023-09-01'\n",
    "# L9startDate = \"2023-07-01\"\n",
    "# L8startDate = \"2023-07-31\"\n",
    "L9endDate = '2023-10-31'\n",
    "L8endDate = '2023-10-31'\n",
    "\n",
    "# ndwi threshold\n",
    "ndwi_threshold = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divideDates(startDate, endDate):\n",
    "    \"\"\"\n",
    "    Divide the timeframe into years\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    startDate: str\n",
    "        start date\n",
    "    endDate: str\n",
    "        end date\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        list of tuples of start and end dates\n",
    "    \"\"\"\n",
    "\n",
    "    startYear = pd.to_datetime(startDate).year\n",
    "    endYear = pd.to_datetime(endDate).year\n",
    "\n",
    "    dates = []\n",
    "    for year in range(startYear, endYear + 1):\n",
    "        if year == startYear and year == endYear:\n",
    "            dates.append((startDate, endDate))\n",
    "        elif year == startYear:\n",
    "            dates.append((startDate, f\"{year}-12-31\"))\n",
    "        elif year == endYear:\n",
    "            dates.append((f\"{year}-01-01\", endDate))\n",
    "        else:\n",
    "            dates.append((f\"{year}-01-01\", f\"{year}-12-31\"))\n",
    "\n",
    "    return dates\n",
    "\n",
    "\n",
    "def prepL8(image):\n",
    "    \"\"\"\n",
    "    Prepare Landsat 8 image for analysis\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    image: ee.Image\n",
    "        Landsat 8 image\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    ee.Image\n",
    "        prepared Landsat 8 image\n",
    "    \"\"\"\n",
    "\n",
    "    # develop masks for unwanted pixels (fill, dilated cloud, cirrus, cloud, cloud shadow, snow)\n",
    "    qa_mask = image.select(\"QA_PIXEL\").bitwiseAnd(int(\"111111\", 2)).eq(0)\n",
    "    saturation_mask = image.select(\"QA_RADSAT\").eq(0)\n",
    "\n",
    "    # apply scaling factors to the appropriate bands\n",
    "    def getFactorImage(factorNames):\n",
    "        factorList = image.toDictionary().select(factorNames).values()\n",
    "        return ee.Image.constant(factorList)\n",
    "\n",
    "    scaleImg = getFactorImage([\"REFLECTANCE_MULT_BAND_.|TEMPERATURE_MULT_BAND_ST_B10\"])\n",
    "    offsetImg = getFactorImage([\"REFLECTANCE_ADD_BAND_.|TEMPERATURE_ADD_BAND_ST_B10\"])\n",
    "    scaled = image.select(\"SR_B.|ST_B10\").multiply(scaleImg).add(offsetImg)\n",
    "\n",
    "    # replace original bands with scaled bands and apply masks\n",
    "    return (\n",
    "        image.addBands(scaled, overwrite=True)\n",
    "        .updateMask(qa_mask)\n",
    "        .updateMask(saturation_mask)\n",
    "    )\n",
    "\n",
    "\n",
    "def addNDWI(image):\n",
    "    \"\"\"\n",
    "    Add NDWI band to image\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    image: ee.Image\n",
    "        Landsat 8 image\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    ee.Image\n",
    "        Landsat 8 image with NDWI band\n",
    "    \"\"\"\n",
    "\n",
    "    ndwi = image.expression(\n",
    "        \"NDWI = (green - NIR)/(green + NIR)\",\n",
    "        {\"green\": image.select(\"SR_B3\"), \"NIR\": image.select(\"SR_B5\")},\n",
    "    ).rename(\"NDWI\")\n",
    "\n",
    "    return image.addBands(ndwi)\n",
    "\n",
    "\n",
    "def addNDVI(image):\n",
    "    \"\"\"\n",
    "    Add NDVI band to image\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    image: ee.Image\n",
    "        Landsat 8 image\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    ee.Image\n",
    "        Landsat 8 image with NDVI band\n",
    "    \"\"\"\n",
    "\n",
    "    # ndvi = image.expression(\n",
    "    #     \"NDVI = (NIR - red)/(NIR + red)\",\n",
    "    #     {\"red\": image.select(\"SR_B4\"), \"NIR\": image.select(\"SR_B5\")},\n",
    "    # ).rename(\"NDVI\")\n",
    "\n",
    "    ndvi = image.normalizedDifference([\"SR_B5\", \"SR_B4\"]).rename(\"NDVI\")\n",
    "\n",
    "    return image.addBands(ndvi)\n",
    "\n",
    "\n",
    "def addCelcius(image):\n",
    "    \"\"\"\n",
    "    Add Celcius band to image\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    image: ee.Image\n",
    "        Landsat 8 image\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    ee.Image\n",
    "        Landsat 8 image with Celcius band\n",
    "    \"\"\"\n",
    "    celcius = image.select(\"ST_B10\").subtract(273.15).rename(\"Celcius\")\n",
    "\n",
    "    return image.addBands(celcius)\n",
    "\n",
    "\n",
    "def extractTempSeries(\n",
    "    reservoir,\n",
    "    startDate,\n",
    "    endDate,\n",
    "    ndwi_threshold=0.2,\n",
    "    imageCollection=\"LANDSAT/LC09/C02/T1_L2\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Extract temperature time series for a reservoir\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    reservoir: ee.Feature\n",
    "        reservoir\n",
    "    startDate: str\n",
    "        start date\n",
    "    endDate: str\n",
    "        end date\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    ee.ImageCollection\n",
    "        temperature time series\n",
    "    \"\"\"\n",
    "\n",
    "    L8 = (\n",
    "        ee.ImageCollection(imageCollection)\n",
    "        .filterDate(startDate, endDate)\n",
    "        .filterBounds(reservoir)\n",
    "    )\n",
    "\n",
    "    # def extractWaterTemp(date):\n",
    "    def extractData(date):\n",
    "        date = ee.Date(date)\n",
    "        # prepare Landsat 8 image and add the NDWI band, and Celcius band\n",
    "        processedL8 = (\n",
    "            L8.filterDate(date, date.advance(1, \"day\"))\n",
    "            .map(prepL8)\n",
    "            .map(addCelcius)\n",
    "            .map(addNDWI)\n",
    "            .map(addNDVI)\n",
    "        )\n",
    "\n",
    "        # # get quality NDWI and use it as the water mask\n",
    "        # ndwi = processedL8.qualityMosaic(\"NDWI\").select(\"NDWI\")\n",
    "        # waterMask = ndwi.gte(ndwi_threshold)\n",
    "        # nonWaterMask = ndwi.lt(ndwi_threshold)\n",
    "\n",
    "        mosaic = processedL8.mosaic()\n",
    "        waterMask = mosaic.select(\"QA_PIXEL\").bitwiseAnd(int(\"10000000\", 2)).neq(0)\n",
    "        nonWaterMask = mosaic.select(\"QA_PIXEL\").bitwiseAnd(int(\"10000000\", 2)).eq(0)\n",
    "\n",
    "        # find the mean of the images in the collection\n",
    "        meanL8water = (\n",
    "            processedL8.reduce(ee.Reducer.mean())\n",
    "            # .addBands(ndwi, [\"NDWI\"], True)\n",
    "            .updateMask(waterMask)\n",
    "            .set(\"system:time_start\", date)\n",
    "        )\n",
    "        meanL8nonwater = (\n",
    "            processedL8.reduce(ee.Reducer.mean())\n",
    "            # .addBands(ndwi, [\"NDWI\"], True)\n",
    "            .updateMask(nonWaterMask)\n",
    "            .set(\"system:time_start\", date)\n",
    "        )\n",
    "\n",
    "        # get the mean temperature of the reservoir\n",
    "        watertemp = meanL8water.select([\"Celcius_mean\"]).reduceRegion(\n",
    "            reducer=ee.Reducer.mean(), geometry=reservoir.geometry(), scale=30\n",
    "        )\n",
    "        landtemp = meanL8nonwater.select([\"Celcius_mean\"]).reduceRegion(\n",
    "            reducer=ee.Reducer.mean(), geometry=reservoir.geometry(), scale=30\n",
    "        )\n",
    "        ndvi = meanL8nonwater.select([\"NDVI_mean\"]).reduceRegion(\n",
    "            reducer=ee.Reducer.mean(), geometry=reservoir.geometry(), scale=30\n",
    "        )\n",
    "\n",
    "        return ee.Feature(\n",
    "            None,\n",
    "            {\n",
    "                \"date\": date.format(\"YYYY-MM-dd\"),\n",
    "                \"watertemp(C)\": watertemp,\n",
    "                \"landtemp(C)\": landtemp,\n",
    "                \"NDVI\": ndvi,\n",
    "            },\n",
    "        )\n",
    "\n",
    "    def extractLandTemp(date):\n",
    "        date = ee.Date(date)\n",
    "        # prepare Landsat 8 image and add the NDWI band, and Celcius band\n",
    "        processedL8 = (\n",
    "            L8.filterDate(date, date.advance(1, \"day\"))\n",
    "            .map(prepL8)\n",
    "            .map(addCelcius)\n",
    "            .map(addNDWI)\n",
    "        )\n",
    "\n",
    "        # get quality NDWI and use it as the water mask\n",
    "        ndwi = processedL8.qualityMosaic(\"NDWI\").select(\"NDWI\")\n",
    "        nonWaterMask = ndwi.lt(ndwi_threshold)\n",
    "\n",
    "        # find the mean of the images in the collection\n",
    "        meanL8 = (\n",
    "            processedL8.reduce(ee.Reducer.mean())\n",
    "            .addBands(ndwi, [\"NDWI\"], True)\n",
    "            .updateMask(nonWaterMask)\n",
    "            .set(\"system:time_start\", date)\n",
    "        )\n",
    "\n",
    "        # get the mean temperature of the reservoir\n",
    "        temp = meanL8.select([\"Celcius_mean\"]).reduceRegion(\n",
    "            reducer=ee.Reducer.mean(), geometry=reservoir.geometry(), scale=30\n",
    "        )\n",
    "\n",
    "        return ee.Feature(None, {\"date\": date.format(\"YYYY-MM-dd\"), \"temp(C)\": temp})\n",
    "\n",
    "    dates = ee.List(\n",
    "        L8.map(\n",
    "            lambda image: ee.Feature(None, {\"date\": image.date().format(\"YYYY-MM-dd\")})\n",
    "        )\n",
    "        .distinct(\"date\")\n",
    "        .aggregate_array(\"date\")\n",
    "    )\n",
    "\n",
    "    # waterTempSeries = ee.FeatureCollection(dates.map(extractWaterTemp))\n",
    "    # landTempSeries = ee.FeatureCollection(dates.map(extractLandTemp))\n",
    "\n",
    "    dataSeries = ee.FeatureCollection(dates.map(extractData))\n",
    "\n",
    "    # return waterTempSeries, landTempSeries\n",
    "    return dataSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ee_to_df(featureCollection):\n",
    "    \"\"\"\n",
    "    Convert an ee.FeatureCollection to a pandas.DataFrame\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    featureCollection: ee.FeatureCollection\n",
    "        feature collection\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    columns = featureCollection.first().propertyNames().getInfo()\n",
    "    rows = (\n",
    "        featureCollection.reduceColumns(ee.Reducer.toList(len(columns)), columns)\n",
    "        .values()\n",
    "        .get(0)\n",
    "        .getInfo()\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=columns)\n",
    "    df.drop(columns=[\"system:index\"], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def download_ee_csv(downloadUrl):\n",
    "    \"\"\"\n",
    "    Download an ee.FeatureCollection as a csv file\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    downloadUrl: str\n",
    "        download url\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(downloadUrl)\n",
    "    df.drop(columns=[\"system:index\", \".geo\"], inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entryToDB(\n",
    "    data, table_name, reach_name, connection, date_col=\"date\", value_col=\"value\"\n",
    "):\n",
    "    data = data.copy()\n",
    "    data[date_col] = pd.to_datetime(data[date_col])\n",
    "    data = data[[date_col, value_col]]\n",
    "    data = data.dropna()\n",
    "    # data = data[data[value_col] != -9999]\n",
    "    data = data.sort_values(by=date_col)\n",
    "\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    for i, row in data.iterrows():\n",
    "        query = f\"\"\"\n",
    "        INSERT INTO {table_name} (Date, ReachID, Value)\n",
    "        SELECT '{row[date_col]}', (SELECT ReachID FROM Reaches WHERE Name = \"{reach_name}\"), {row[value_col]}\n",
    "        WHERE NOT EXISTS (SELECT * FROM {table_name} WHERE Date = '{row[date_col]}' AND ReachID = (SELECT ReachID FROM Reaches WHERE Name = \"{reach_name}\"))\n",
    "        \"\"\"\n",
    "\n",
    "        cursor.execute(query)\n",
    "        connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reachwiseExtraction(\n",
    "    reaches,\n",
    "    reach_id,\n",
    "    startDate,\n",
    "    endDate,\n",
    "    ndwi_threshold=0.2,\n",
    "    imageCollection=\"LANDSAT/LC09/C02/T1_L2\",\n",
    "    checkpoint_path=None,\n",
    "    connection=None,\n",
    "):\n",
    "    if checkpoint_path is None:\n",
    "        checkpoint = {\"river_index\": 0, \"reach_index\": 0}\n",
    "    else:\n",
    "        with open(checkpoint_path, \"r\") as f:\n",
    "            checkpoint = json.load(f)\n",
    "\n",
    "    # if reach_ids is None:\n",
    "    #     ee_reach_ids = reaches.select(\"reach_id\", retainGeometry=False).getInfo()\n",
    "    #     reach_ids = [i[\"properties\"][\"reach_id\"] for i in ee_reach_ids[\"features\"]][\n",
    "    #         checkpoint[\"reach_index\"] :\n",
    "    #     ]\n",
    "    #     # reach_ids = gdf[\"reach_id\"].tolist()\n",
    "\n",
    "    # extract temperature time series for each reservoir\n",
    "    # for reach_id in reach_ids:\n",
    "    # print(f\"Reach {reach_id} started!\")\n",
    "    dates = divideDates(startDate, endDate)\n",
    "    waterTempSeriesList = []\n",
    "    landTempSeriesList = []\n",
    "\n",
    "    dataSeriesList = []\n",
    "\n",
    "    # if os.path.isfile(data_dir / \"reaches\" / f\"{reach_id}_watertemp.csv\"):\n",
    "    #     existing_df = pd.read_csv(\n",
    "    #         data_dir / \"reaches\" / f\"{reach_id}_watertemp.csv\"\n",
    "    #     )\n",
    "    #     existing_df[\"date\"] = pd.to_datetime(existing_df[\"date\"])\n",
    "    #     waterTempSeriesList.append(existing_df)\n",
    "    #     # print(\"File exists!\")\n",
    "\n",
    "    # if os.path.isfile(data_dir / \"reaches\" / f\"{reach_id}_landtemp.csv\"):\n",
    "    #     existing_df = pd.read_csv(data_dir / \"reaches\" / f\"{reach_id}_landtemp.csv\")\n",
    "    #     existing_df[\"date\"] = pd.to_datetime(existing_df[\"date\"])\n",
    "    #     landTempSeriesList.append(existing_df)\n",
    "    #     # print(\"File exists!\")\n",
    "\n",
    "    # if os.path.isfile(data_dir / \"reaches\" / f\"{reach_id}.csv\"):\n",
    "    #     existing_df = pd.read_csv(data_dir / \"reaches\" / f\"{reach_id}.csv\")\n",
    "    #     existing_df[\"date\"] = pd.to_datetime(existing_df[\"date\"])\n",
    "    #     dataSeriesList.append(existing_df)\n",
    "    #     # print(\"File exists!\")\n",
    "\n",
    "    # if os.path.isfile(data_dir / \"reaches\" / f\"{reach_id}.csv\"):\n",
    "    #     existing_df = pd.read_csv(data_dir / \"reaches\" / f\"{reach_id}.csv\")\n",
    "    #     existing_df[\"date\"] = pd.to_datetime(existing_df[\"date\"])\n",
    "    #     dataSeriesList.append(existing_df)\n",
    "\n",
    "    for date in dates:\n",
    "        startDate_ = date[0]\n",
    "        endDate_ = date[1]\n",
    "\n",
    "        reservoir = reaches.filter(ee.Filter.eq(\"reach_id\", ee.String(reach_id)))\n",
    "        # waterTempSeries, landTempSeries= extractTempSeries(\n",
    "        #     reservoir, startDate_, endDate_, ndwi_threshold, imageCollection\n",
    "        # )\n",
    "        # waterTempSeries = geemap.ee_to_pandas(waterTempSeries)\n",
    "        # landTempSeries = geemap.ee_to_pandas(landTempSeries)\n",
    "        dataSeries = extractTempSeries(\n",
    "            reservoir, startDate_, endDate_, ndwi_threshold, imageCollection\n",
    "        )\n",
    "        dataSeries = geemap.ee_to_pandas(dataSeries)\n",
    "\n",
    "        # convert date column to datetime\n",
    "        # waterTempSeries[\"date\"] = pd.to_datetime(waterTempSeries[\"date\"])\n",
    "        # landTempSeries[\"date\"] = pd.to_datetime(landTempSeries[\"date\"])\n",
    "        dataSeries[\"date\"] = pd.to_datetime(dataSeries[\"date\"])\n",
    "\n",
    "        # waterTempSeries[\"temp(C)\"] = (\n",
    "        #     waterTempSeries[\"temp(C)\"]\n",
    "        #     .apply(lambda x: x[\"Celcius_mean\"])\n",
    "        #     .astype(float)\n",
    "        # )\n",
    "        # landTempSeries[\"temp(C)\"] = (\n",
    "        #     landTempSeries[\"temp(C)\"]\n",
    "        #     .apply(lambda x: x[\"Celcius_mean\"])\n",
    "        #     .astype(float)\n",
    "        # )\n",
    "\n",
    "        dataSeries[\"watertemp(C)\"] = (\n",
    "            dataSeries[\"watertemp(C)\"]\n",
    "            .apply(lambda x: x[\"Celcius_mean\"])\n",
    "            .astype(float)\n",
    "        )\n",
    "        dataSeries[\"landtemp(C)\"] = (\n",
    "            dataSeries[\"landtemp(C)\"]\n",
    "            .apply(lambda x: x[\"Celcius_mean\"])\n",
    "            .astype(float)\n",
    "        )\n",
    "        dataSeries[\"NDVI\"] = (\n",
    "            dataSeries[\"NDVI\"].apply(lambda x: x[\"NDVI_mean\"]).astype(float)\n",
    "        )\n",
    "\n",
    "        # append time series to list\n",
    "        # waterTempSeriesList.append(waterTempSeries)\n",
    "        # landTempSeriesList.append(landTempSeries)\n",
    "        dataSeriesList.append(dataSeries)\n",
    "\n",
    "        s_time = randint(5, 10)\n",
    "        time.sleep(s_time)\n",
    "\n",
    "    # concatenate all time series\n",
    "    # waterTempSeries_df = pd.concat(waterTempSeriesList, ignore_index=True)\n",
    "    # landTempSeries_df = pd.concat(landTempSeriesList, ignore_index=True)\n",
    "    dataSeries_df = pd.concat(dataSeriesList, ignore_index=True)\n",
    "\n",
    "    # sort by date\n",
    "    # waterTempSeries_df.sort_values(by=\"date\", inplace=True)\n",
    "    # landTempSeries_df.sort_values(by=\"date\", inplace=True)\n",
    "    dataSeries_df.sort_values(by=\"date\", inplace=True)\n",
    "    # #drop null values\n",
    "    # # waterTempSeries_df.dropna(inplace=True)\n",
    "    # # landTempSeries_df.dropna(inplace=True)\n",
    "    # dataSeries_df.dropna(inplace=True)\n",
    "    # remove duplicates\n",
    "    # waterTempSeries_df.drop_duplicates(subset=\"date\", inplace=True)\n",
    "    # landTempSeries_df.drop_duplicates(subset=\"date\", inplace=True)\n",
    "    dataSeries_df.drop_duplicates(subset=\"date\", inplace=True)\n",
    "\n",
    "    # save time series to csv\n",
    "    # waterTempSeries_df.to_csv(\n",
    "    #     data_dir / \"reaches\" / f\"{reach_id}_watertemp.csv\", index=False\n",
    "    # )\n",
    "    # landTempSeries_df.to_csv(\n",
    "    #     data_dir / \"reaches\" / f\"{reach_id}_landtemp.csv\", index=False\n",
    "    # )\n",
    "    # dataSeries_df.to_csv(\n",
    "    #     data_dir / \"reaches\" / f\"{reach_id}.csv\", index=False\n",
    "    # )\n",
    "\n",
    "    # land temp\n",
    "    entryToDB(\n",
    "        dataSeries_df,\n",
    "        \"ReachLandsatLandTemp\",\n",
    "        reach_id,\n",
    "        connection,\n",
    "        date_col=\"date\",\n",
    "        value_col=\"landtemp(C)\",\n",
    "    )\n",
    "    # water temp\n",
    "    entryToDB(\n",
    "        dataSeries_df,\n",
    "        \"ReachLandsatWaterTemp\",\n",
    "        reach_id,\n",
    "        connection,\n",
    "        date_col=\"date\",\n",
    "        value_col=\"watertemp(C)\",\n",
    "    )\n",
    "    # NDVI\n",
    "    entryToDB(\n",
    "        dataSeries_df,\n",
    "        \"ReachNDVI\",\n",
    "        reach_id,\n",
    "        connection,\n",
    "        date_col=\"date\",\n",
    "        value_col=\"NDVI\",\n",
    "    )\n",
    "\n",
    "    # checkpoint[\"reach_index\"] += 1\n",
    "    # json.dump(checkpoint, open(checkpoint_path, \"w\"))\n",
    "    # print(f\"Reach {reach_id} done!\")\n",
    "    # s_time = randint(30, 60)\n",
    "    # time.sleep(s_time)\n",
    "\n",
    "    # print(\"All done!\")\n",
    "\n",
    "    # TODO: Delete this section onwards\n",
    "    # # extract temperature time series for each reservoir\n",
    "    # for reach_id in reach_ids:\n",
    "    #     # print(f\"Reach {reach_id} started!\")\n",
    "    #     dates = divideDates(startDate, endDate)\n",
    "    #     waterTempSeriesList = []\n",
    "    #     landTempSeriesList = []\n",
    "\n",
    "    #     dataSeriesList = []\n",
    "\n",
    "    #     # if os.path.isfile(data_dir / \"reaches\" / f\"{reach_id}_watertemp.csv\"):\n",
    "    #     #     existing_df = pd.read_csv(\n",
    "    #     #         data_dir / \"reaches\" / f\"{reach_id}_watertemp.csv\"\n",
    "    #     #     )\n",
    "    #     #     existing_df[\"date\"] = pd.to_datetime(existing_df[\"date\"])\n",
    "    #     #     waterTempSeriesList.append(existing_df)\n",
    "    #     #     # print(\"File exists!\")\n",
    "\n",
    "    #     # if os.path.isfile(data_dir / \"reaches\" / f\"{reach_id}_landtemp.csv\"):\n",
    "    #     #     existing_df = pd.read_csv(data_dir / \"reaches\" / f\"{reach_id}_landtemp.csv\")\n",
    "    #     #     existing_df[\"date\"] = pd.to_datetime(existing_df[\"date\"])\n",
    "    #     #     landTempSeriesList.append(existing_df)\n",
    "    #     #     # print(\"File exists!\")\n",
    "\n",
    "    #     # if os.path.isfile(data_dir / \"reaches\" / f\"{reach_id}.csv\"):\n",
    "    #     #     existing_df = pd.read_csv(data_dir / \"reaches\" / f\"{reach_id}.csv\")\n",
    "    #     #     existing_df[\"date\"] = pd.to_datetime(existing_df[\"date\"])\n",
    "    #     #     dataSeriesList.append(existing_df)\n",
    "    #     #     # print(\"File exists!\")\n",
    "\n",
    "    #     for date in dates:\n",
    "    #         startDate_ = date[0]\n",
    "    #         endDate_ = date[1]\n",
    "\n",
    "    #         reservoir = reaches.filter(ee.Filter.eq(\"reach_id\", ee.String(reach_id)))\n",
    "    #         # waterTempSeries, landTempSeries= extractTempSeries(\n",
    "    #         #     reservoir, startDate_, endDate_, ndwi_threshold, imageCollection\n",
    "    #         # )\n",
    "    #         # waterTempSeries = geemap.ee_to_pandas(waterTempSeries)\n",
    "    #         # landTempSeries = geemap.ee_to_pandas(landTempSeries)\n",
    "    #         dataSeries = extractTempSeries(\n",
    "    #             reservoir, startDate_, endDate_, ndwi_threshold, imageCollection\n",
    "    #         )\n",
    "    #         dataSeries = geemap.ee_to_pandas(dataSeries)\n",
    "\n",
    "    #         # convert date column to datetime\n",
    "    #         # waterTempSeries[\"date\"] = pd.to_datetime(waterTempSeries[\"date\"])\n",
    "    #         # landTempSeries[\"date\"] = pd.to_datetime(landTempSeries[\"date\"])\n",
    "    #         dataSeries[\"date\"] = pd.to_datetime(dataSeries[\"date\"])\n",
    "\n",
    "    #         # waterTempSeries[\"temp(C)\"] = (\n",
    "    #         #     waterTempSeries[\"temp(C)\"]\n",
    "    #         #     .apply(lambda x: x[\"Celcius_mean\"])\n",
    "    #         #     .astype(float)\n",
    "    #         # )\n",
    "    #         # landTempSeries[\"temp(C)\"] = (\n",
    "    #         #     landTempSeries[\"temp(C)\"]\n",
    "    #         #     .apply(lambda x: x[\"Celcius_mean\"])\n",
    "    #         #     .astype(float)\n",
    "    #         # )\n",
    "\n",
    "    #         dataSeries[\"watertemp(C)\"] = (\n",
    "    #             dataSeries[\"watertemp(C)\"]\n",
    "    #             .apply(lambda x: x[\"Celcius_mean\"])\n",
    "    #             .astype(float)\n",
    "    #         )\n",
    "    #         dataSeries[\"landtemp(C)\"] = (\n",
    "    #             dataSeries[\"landtemp(C)\"]\n",
    "    #             .apply(lambda x: x[\"Celcius_mean\"])\n",
    "    #             .astype(float)\n",
    "    #         )\n",
    "    #         dataSeries[\"NDVI\"] = (\n",
    "    #             dataSeries[\"NDVI\"].apply(lambda x: x[\"NDVI_mean\"]).astype(float)\n",
    "    #         )\n",
    "\n",
    "    #         # append time series to list\n",
    "    #         # waterTempSeriesList.append(waterTempSeries)\n",
    "    #         # landTempSeriesList.append(landTempSeries)\n",
    "    #         dataSeriesList.append(dataSeries)\n",
    "\n",
    "    #         s_time = randint(5, 10)\n",
    "    #         time.sleep(s_time)\n",
    "\n",
    "    #     # concatenate all time series\n",
    "    #     # waterTempSeries_df = pd.concat(waterTempSeriesList, ignore_index=True)\n",
    "    #     # landTempSeries_df = pd.concat(landTempSeriesList, ignore_index=True)\n",
    "    #     dataSeries_df = pd.concat(dataSeriesList, ignore_index=True)\n",
    "\n",
    "    #     # sort by date\n",
    "    #     # waterTempSeries_df.sort_values(by=\"date\", inplace=True)\n",
    "    #     # landTempSeries_df.sort_values(by=\"date\", inplace=True)\n",
    "    #     dataSeries_df.sort_values(by=\"date\", inplace=True)\n",
    "    #     # #drop null values\n",
    "    #     # # waterTempSeries_df.dropna(inplace=True)\n",
    "    #     # # landTempSeries_df.dropna(inplace=True)\n",
    "    #     # dataSeries_df.dropna(inplace=True)\n",
    "    #     # remove duplicates\n",
    "    #     # waterTempSeries_df.drop_duplicates(subset=\"date\", inplace=True)\n",
    "    #     # landTempSeries_df.drop_duplicates(subset=\"date\", inplace=True)\n",
    "    #     dataSeries_df.drop_duplicates(subset=\"date\", inplace=True)\n",
    "\n",
    "    #     # save time series to csv\n",
    "    #     # waterTempSeries_df.to_csv(\n",
    "    #     #     data_dir / \"reaches\" / f\"{reach_id}_watertemp.csv\", index=False\n",
    "    #     # )\n",
    "    #     # landTempSeries_df.to_csv(\n",
    "    #     #     data_dir / \"reaches\" / f\"{reach_id}_landtemp.csv\", index=False\n",
    "    #     # )\n",
    "    #     # dataSeries_df.to_csv(\n",
    "    #     #     data_dir / \"reaches\" / f\"{reach_id}.csv\", index=False\n",
    "    #     # )\n",
    "\n",
    "    #     # land temp\n",
    "    #     entryToDB(\n",
    "    #         dataSeries_df,\n",
    "    #         \"ReachLandsatLandTemp\",\n",
    "    #         reach_id,\n",
    "    #         connection,\n",
    "    #         date_col=\"date\",\n",
    "    #         value_col=\"landtemp(C)\",\n",
    "    #     )\n",
    "    #     # water temp\n",
    "    #     entryToDB(\n",
    "    #         dataSeries_df,\n",
    "    #         \"ReachLandsatWaterTemp\",\n",
    "    #         reach_id,\n",
    "    #         connection,\n",
    "    #         date_col=\"date\",\n",
    "    #         value_col=\"watertemp(C)\",\n",
    "    #     )\n",
    "    #     # NDVI\n",
    "    #     entryToDB(\n",
    "    #         dataSeries_df,\n",
    "    #         \"ReachNDVI\",\n",
    "    #         reach_id,\n",
    "    #         connection,\n",
    "    #         date_col=\"date\",\n",
    "    #         value_col=\"NDVI\",\n",
    "    #     )\n",
    "\n",
    "    #     checkpoint[\"reach_index\"] += 1\n",
    "    #     json.dump(checkpoint, open(checkpoint_path, \"w\"))\n",
    "    #     print(f\"Reach {reach_id} done!\")\n",
    "    #     # s_time = randint(30, 60)\n",
    "    #     # time.sleep(s_time)\n",
    "\n",
    "    # # print(\"All done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(river_shp)\n",
    "gdf = gdf.to_crs(epsg=4326)\n",
    "\n",
    "rivers = gdf[\"GNIS_Name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runExtraction(data_dir, checkpoint_path=None, connection=None):\n",
    "    if checkpoint_path is None:\n",
    "        checkpoint = {\"river_index\": 0, \"reach_index\": 0}\n",
    "    else:\n",
    "        with open(checkpoint_path, \"r\") as f:\n",
    "            checkpoint = json.load(f)\n",
    "\n",
    "    # gdf = gpd.read_file(river_shp)\n",
    "    # gdf = gdf.to_crs(epsg=4326)\n",
    "\n",
    "    # unique_rivers = gdf[\"GNIS_Name\"].unique()\n",
    "    # unique_rivers = gdf[\"GNIS_Name\"].unique()[checkpoint[\"river_index\"]:]\n",
    "    unique_rivers = rivers[checkpoint[\"river_index\"] :]\n",
    "    # unique_rivers = redo_rivers[checkpoint[\"river_index\"]:]\n",
    "\n",
    "    for river in unique_rivers:\n",
    "        gdf[gdf[\"GNIS_Name\"] == river].to_file(data_dir / \"reaches\" / \"rivers.shp\")\n",
    "        reach_ids = gdf[gdf[\"GNIS_Name\"] == river][\"reach_id\"].tolist()\n",
    "        reach_ids = reach_ids[checkpoint[\"reach_index\"] :]\n",
    "\n",
    "        reaches = geemap.shp_to_ee(data_dir / \"reaches\" / \"rivers.shp\")\n",
    "\n",
    "        if reach_ids is None:\n",
    "            ee_reach_ids = reaches.select(\"reach_id\", retainGeometry=False).getInfo()\n",
    "            reach_ids = [i[\"properties\"][\"reach_id\"] for i in ee_reach_ids[\"features\"]][\n",
    "                checkpoint[\"reach_index\"] :\n",
    "            ]\n",
    "            # reach_ids = gdf[\"reach_id\"].tolist()\n",
    "\n",
    "        for reach_id in reach_ids:\n",
    "            # Landsat8 Data\n",
    "            reachwiseExtraction(\n",
    "                reaches,\n",
    "                reach_id,\n",
    "                L8startDate,\n",
    "                L8endDate,\n",
    "                ndwi_threshold,\n",
    "                imageCollection=\"LANDSAT/LC08/C02/T1_L2\",\n",
    "                checkpoint_path=checkpoint_path,\n",
    "                connection=connection,\n",
    "            )\n",
    "\n",
    "            # Landsat9 Data\n",
    "            reachwiseExtraction(\n",
    "                reaches,\n",
    "                reach_id,\n",
    "                L9startDate,\n",
    "                L9endDate,\n",
    "                ndwi_threshold,\n",
    "                imageCollection=\"LANDSAT/LC09/C02/T1_L2\",\n",
    "                checkpoint_path=checkpoint_path,\n",
    "                connection=connection,\n",
    "            )\n",
    "\n",
    "            checkpoint[\"reach_index\"] += 1\n",
    "            json.dump(checkpoint, open(checkpoint_path, \"w\"))\n",
    "            print(f\"Reach {reach_id} done!\")\n",
    "\n",
    "        checkpoint[\"reach_index\"] = 0\n",
    "        checkpoint[\"river_index\"] += 1\n",
    "        json.dump(checkpoint, open(checkpoint_path, \"w\"))\n",
    "\n",
    "        # s_time = randint(30,120)\n",
    "        # time.sleep(s_time)\n",
    "\n",
    "        print(f\"{river} done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf[\"GNIS_Name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(data_dir / \"reaches\" / \"checkpoint.json\", \"r\") as f:\n",
    "        checkpoint = json.load(f)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Creating new checkpoint...\")\n",
    "    checkpoint = {\"river_index\": 0, \"reach_index\": 0}\n",
    "    # save checkpoint\n",
    "    json.dump(checkpoint, open(data_dir / \"reaches\" / \"checkpoint.json\", \"w\"))\n",
    "\n",
    "repeated_tries = 0\n",
    "\n",
    "# while checkpoint[\"river_index\"] < len(gdf[\"GNIS_Name\"].unique()):\n",
    "while checkpoint[\"river_index\"] < len(rivers):\n",
    "    # while checkpoint[\"river_index\"] < len(redo_rivers):\n",
    "    try:\n",
    "        runExtraction(data_dir, data_dir / \"reaches\" / \"checkpoint.json\", connection)\n",
    "        repeated_tries = 0  # reset repeated_tries\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        # sleep for 0.5 - 3 minutes\n",
    "        s_time = randint(30, 120)\n",
    "        print(f\"Sleeping for {s_time} seconds...\")\n",
    "        time.sleep(s_time)\n",
    "        print(\"Restarting from checkpoint...\")  # restart from checkpoint\n",
    "\n",
    "        repeated_tries += 1  # increment repeated_tries\n",
    "\n",
    "        # if repeated_tries > 3, increment river_index and reset reach_index\n",
    "        if repeated_tries > 3:\n",
    "            checkpoint[\"reach_index\"] += 1\n",
    "            current_river = gdf[\"GNIS_Name\"].unique()[checkpoint[\"river_index\"]]\n",
    "            if checkpoint[\"reach_index\"] >= len(\n",
    "                gdf[gdf[\"GNIS_Name\"] == current_river][\"reach_id\"].tolist()\n",
    "            ):\n",
    "                checkpoint[\"reach_index\"] = 0\n",
    "                checkpoint[\"river_index\"] += 1\n",
    "            repeated_tries = 0\n",
    "\n",
    "            # save checkpoint\n",
    "            json.dump(checkpoint, open(data_dir / \"reaches\" / \"checkpoint.json\", \"w\"))\n",
    "    finally:\n",
    "        # save checkpoint\n",
    "        with open(data_dir / \"reaches\" / \"checkpoint.json\", \"r\") as f:\n",
    "            checkpoint = json.load(f)\n",
    "\n",
    "# reset checkpoint if all rivers are done\n",
    "# if checkpoint[\"river_index\"] >= len(gdf[\"GNIS_Name\"].unique()):\n",
    "if checkpoint[\"river_index\"] >= len(rivers):\n",
    "    checkpoint[\"river_index\"] = 0\n",
    "    checkpoint[\"reach_index\"] = 0\n",
    "    json.dump(checkpoint, open(data_dir / \"reaches\" / \"checkpoint.json\", \"w\"))\n",
    "\n",
    "print(\"All done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydrothermal-history",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
