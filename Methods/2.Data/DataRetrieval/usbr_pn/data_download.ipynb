{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_dir = Path(\"../../../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to format the url\n",
    "def format_url(station_name: str, pcodes: list, start: datetime, end: datetime):\n",
    "    \"\"\"Formats the url for the USBR PN data query.\n",
    "    Args:\n",
    "        station_name (str): The station name.\n",
    "        pcodes (list): The list of pcodes.\n",
    "        start (datetime): The start date.\n",
    "        end (datetime): The end date.\n",
    "    Returns:\n",
    "        url (str): The formatted url.\n",
    "    \"\"\"\n",
    "    url = (\n",
    "        f\"https://www.usbr.gov/pn-bin/daily.pl?station={station_name.lower()}&format=csv&year={start.year}&month={start.month}&day={start.day}&year={end.year}&month={end.month}&day={end.day}\"\n",
    "        + \"\".join([\"&pcode=\" + pcode.strip(\" \").lower() for pcode in pcodes])\n",
    "    )\n",
    "\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to download the data for a station\n",
    "def download_data(station_name: str, pcodes: list, start: datetime, end: datetime, path: str):\n",
    "    \"\"\"Downloads the data for a station.\n",
    "    Args:\n",
    "        station_name (str): The station name.\n",
    "        pcodes (list): The list of pcodes.\n",
    "        start (datetime): The start date.\n",
    "        end (datetime): The end date.\n",
    "        path (str): The path to save the data.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # format the url\n",
    "    url = format_url(station_name, pcodes, start, end)\n",
    "\n",
    "    # download the data\n",
    "    r = requests.get(url)\n",
    "\n",
    "    # write the data to a csv file\n",
    "    with open(os.path.join(path, 'raw/usbr', station_name + \".csv\"), \"w\") as f:\n",
    "        f.write(r.text)\n",
    "\n",
    "    # read the csv file\n",
    "    with open(os.path.join(path, 'raw/usbr', station_name + \".csv\"), \"r\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        data = list(reader)\n",
    "\n",
    "    # remove the header\n",
    "    data = data[1:]\n",
    "\n",
    "    # define the column names\n",
    "    column_names = [\"date\"] + pcodes\n",
    "\n",
    "    # write the data to a csv file\n",
    "    with open(os.path.join(path, 'raw/usbr', station_name + \".csv\"), \"w\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(column_names)\n",
    "        writer.writerows(data)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to process the downloaded data\n",
    "def postprocess_data(\n",
    "    station_name: str,\n",
    "    path: str,\n",
    "    grand_id: str = None,\n",
    "    pcodes: list = None,\n",
    "    pcode_keys: dict = None,\n",
    "):\n",
    "    if not grand_id:\n",
    "        grand_id = station_name\n",
    "\n",
    "    # read in the data\n",
    "    # print(path, \"raw/usbr\", \"{}.csv\".format(station_name.upper()))\n",
    "    df = pd.read_csv(\n",
    "        os.path.join(path, \"raw/usbr\", \"{}.csv\".format(station_name.upper()))\n",
    "    )\n",
    "\n",
    "    new_df = pd.DataFrame()\n",
    "    new_df[\"date\"] = df[\"date\"]\n",
    "\n",
    "    # convert the data to the correct units\n",
    "    for pcode in pcodes:\n",
    "        if pcode in pcode_keys.keys():\n",
    "            try:\n",
    "                pcode_keys[pcode][\"constant\"] = pcode_keys[pcode][\"constant\"]\n",
    "            except:\n",
    "                pcode_keys[pcode][\"constant\"] = None\n",
    "            \n",
    "            if pcode_keys[pcode][\"constant\"]:\n",
    "                new_df[pcode_keys[pcode][\"column_name\"]] = (\n",
    "                    df[pcode] * np.prod(pcode_keys[pcode][\"conversion_factors\"])\n",
    "                    + pcode_keys[pcode][\"constant\"]\n",
    "                )\n",
    "            else:\n",
    "                new_df[pcode_keys[pcode][\"column_name\"]] = df[pcode] * np.prod(\n",
    "                    pcode_keys[pcode][\"conversion_factors\"]\n",
    "                )\n",
    "\n",
    "    # save the data\n",
    "    new_df.to_csv(\n",
    "        # os.path.join(path, \"processed\", \"USBR_{}.csv\".format(grand_id)), index=False\n",
    "        os.path.join(path, \"processed\", \"USBR_{}.csv\".format(station_name)), index=False\n",
    "    )\n",
    "    # print(\"processed data for {}\".format(station_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the station names\n",
    "# station_names = [\"crpo\", 'prv', 'prvo', 'kee', 'cle', 'crao']\n",
    "station_names = pd.read_csv(\"pcodes.csv\", header=None)[0]\n",
    "# grand_ids = [None, 91, '91_forebay', 55, 58, None]\n",
    "\n",
    "# define the start and end dates\n",
    "start_date = datetime.strptime(\"1990-01-01\", \"%Y-%m-%d\")\n",
    "end_date = datetime.strptime(\"2023-10-31\", \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the stations json file\n",
    "with open(\"stations.json\", \"r\") as f:\n",
    "    stations_dict = json.load(f)\n",
    "\n",
    "# specify the download folder and make it the current working directory\n",
    "data_dir = proj_dir / \"Data/InSituTemperature\"\n",
    "\n",
    "# if not os.path.exists(path):\n",
    "#     os.makedirs(path)\n",
    "os.makedirs(os.path.join(data_dir, \"raw/usbr\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(data_dir, \"raw/usbr\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(data_dir, \"processed\"), exist_ok=True)\n",
    "\n",
    "# download the data for each station\n",
    "# for station_name, id in zip(station_names, grand_ids):\n",
    "for station_name in station_names:\n",
    "    # if pcodes exist for the station\n",
    "    if \"pcodes\" in stations_dict[station_name.upper()]:\n",
    "        # define the pcodes and pcode keys\n",
    "        pcodes = stations_dict[station_name.upper()][\"pcodes\"]\n",
    "        pcode_keys = stations_dict[\"pcode_keys\"]\n",
    "\n",
    "        # download the data\n",
    "        download_data(station_name.upper(), pcodes, start_date, end_date, data_dir)\n",
    "        # postprocess the data\n",
    "        postprocess_data(station_name.upper(), data_dir, pcodes=pcodes, pcode_keys=pcode_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
