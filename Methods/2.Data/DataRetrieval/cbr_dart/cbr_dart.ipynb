{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data from [Columbia Basin Research](https://www.cbr.washington.edu/)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## River Environment Data\n",
    "\n",
    "Outflow (kcfs), Spill (kcfs), Spill Percent (%), Inflow (kcfs), Temp (Scroll Case) (C), Temperature (C), Barometric Pressure (mmHg), Dissolved Gas (mmHg), Dissolved Gas Percent (%), Turbidity (ft), Elevation (ft)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_dir = Path(\"../../../..\")\n",
    "\n",
    "data_dir = proj_dir / \"Data/InSituTemperature\"\n",
    "\n",
    "# load metadata\n",
    "metadata = json.load(Path(data_dir, \"processed\", \"metadata copy.json\").open(\"r\"))\n",
    "# dart_stations_metadata = pd.read_csv(Path(\"/Users/gdarkwah/Library/CloudStorage/OneDrive-UW/01-Research/01-Hydrothermal History/Methods/data_retrieval/cbr_dart/dart_metadata.csv\"))\n",
    "dart_stations_metadata = pd.read_csv(\n",
    "    Path(proj_dir, \"Methods/data_retrieval/cbr_dart/dart_metadata.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dart_stations_metadata[\"Abbrev\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format the url for the request\n",
    "def format_url(proj: str, startDate: str, endDate: str):\n",
    "    \"\"\"Formats the url for the request for a particular project and date range within the same year\n",
    "    Args:\n",
    "        proj (str): abbreviated form of the project name\n",
    "        startDate (str): start date of the query [YYYY-MM-DD]\n",
    "        endDate (str): end date of the query [YYYY-MM-DD]\n",
    "    Returns:\n",
    "        url (str): formated url for the request\n",
    "    \"\"\"\n",
    "    # convert the dates to datetime objects\n",
    "    startDate = datetime.strptime(startDate, \"%Y-%m-%d\")\n",
    "    endDate = datetime.strptime(endDate, \"%Y-%m-%d\")\n",
    "\n",
    "    # get the year from the start date\n",
    "    year = startDate.year\n",
    "\n",
    "    # get the month and day from the start and end dates\n",
    "    startMonth = startDate.month\n",
    "    startDay = startDate.day\n",
    "    endMonth = endDate.month\n",
    "    endDay = endDate.day\n",
    "\n",
    "    # format the url\n",
    "    url = \"https://www.cbr.washington.edu/dart/cs/php/rpt/river_daily.php?sc=1&outputFormat=csv&year={}&proj={}&span=no&startdate={}%2F{}&enddate={}%2F{}\".format(\n",
    "        year, proj, startMonth, startDay, endMonth, endDay\n",
    "    )\n",
    "\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data from the url and convert it to a csv\n",
    "def get_data(proj: str, startDate: str, endDate: str, path: str):\n",
    "    \"\"\"Gets the data from the url and converts it to a csv\n",
    "    Args:\n",
    "        proj (str): abbreviated form of the project name\n",
    "        startDate (str): start date of the query [YYYY-MM-DD]\n",
    "        endDate (str): end date of the query [YYYY-MM-DD]\n",
    "        path (str): path to the directory where the csv file will be saved\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # capitalize the project name\n",
    "    proj = proj.upper()\n",
    "\n",
    "    # get start year and end year\n",
    "    startYear = datetime.strptime(startDate, \"%Y-%m-%d\").year\n",
    "    endYear = datetime.strptime(endDate, \"%Y-%m-%d\").year\n",
    "\n",
    "    first_data = True\n",
    "\n",
    "    # create a csv file for the data by adding all the data from each year\n",
    "    with open(\n",
    "        os.path.join(path, \"raw/dart\", \"DART_{}.csv\".format(proj)), \"w\", newline=\"\"\n",
    "    ) as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=\",\")\n",
    "        # for each year, take off the lines after the line that begins with 'Notes:'\n",
    "        for year in range(startYear, endYear + 1):\n",
    "            if year == startYear and year == endYear:\n",
    "                # get the url for the request\n",
    "                url = format_url(proj, startDate, endDate)\n",
    "            elif year == startYear:\n",
    "                # get the url for the request\n",
    "                url = format_url(proj, startDate, \"{}-12-31\".format(year))\n",
    "            elif year == endYear:\n",
    "                # get the url for the request\n",
    "                url = format_url(proj, \"{}-01-01\".format(year), endDate)\n",
    "            else:\n",
    "                # get the url for the request\n",
    "                url = format_url(proj, \"{}-01-01\".format(year), \"{}-12-31\".format(year))\n",
    "\n",
    "            # print(url)\n",
    "            # get the data from the url and convert it to csv format\n",
    "            response = requests.get(url)\n",
    "            data = response.text.splitlines()\n",
    "            if (\n",
    "                data[0] == \"<!DOCTYPE html>\"\n",
    "                or data[0] == '<html lang=\"en\" class=\"no-js\">'\n",
    "            ):\n",
    "                pass\n",
    "            else:\n",
    "                for i in range(len(data)):\n",
    "                    if data[i].startswith(\"Notes:\"):\n",
    "                        data = data[:i]\n",
    "                        break\n",
    "                # write the data to the csv file but don't repeat the header row\n",
    "                # print(data[0])\n",
    "                if year == startYear or first_data:\n",
    "                    writer.writerows(csv.reader(data))\n",
    "                    first_data = False\n",
    "                else:\n",
    "                    writer.writerows(csv.reader(data[1:]))\n",
    "                # writer.writerows(csv.reader(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# postprocess the downloaded data\n",
    "def postprocess_data(proj: str, path: str, grand_id: str = None):\n",
    "    # if not grand_id:\n",
    "    #     grand_id = proj\n",
    "\n",
    "    # read in the data\n",
    "    df = pd.read_csv(os.path.join(path, \"raw/dart\", \"DART_{}.csv\".format(proj.upper())))\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.to_csv(\n",
    "        os.path.join(path, \"raw/dart\", \"DART_{}.csv\".format(proj.upper())), index=False\n",
    "    )\n",
    "    df = pd.read_csv(os.path.join(path, \"raw/dart\", \"DART_{}.csv\".format(proj.upper())))\n",
    "\n",
    "    new_df = pd.DataFrame()\n",
    "    new_df[\"date\"] = df[\"Date\"]\n",
    "    new_df[\"outflow (m3/d)\"] = df[\"Outflow (kcfs)\"] * 0.0283168 * 86400 * 1000\n",
    "    new_df[\"inflow (m3/d)\"] = df[\"Inflow (kcfs)\"] * 0.0283168 * 86400 * 1000\n",
    "    new_df[\"spill (m3/d)\"] = df[\"Spill (kcfs)\"] * 0.0283168 * 86400 * 1000\n",
    "    new_df[\"avg water temperature (C)\"] = df[\"Temperature (C)\"]\n",
    "    try:\n",
    "        new_df[\"elevation (m)\"] = df[\"Elevation (ft)\"] * 0.3048\n",
    "    except:\n",
    "        try:\n",
    "            new_df[\"tailwater elevation (m)\"] = df[\"Tailwater Elevation (ft)\"] * 0.3048\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # drop null columns\n",
    "    new_df = new_df.dropna(axis=1, how=\"all\")\n",
    "\n",
    "    # save the data\n",
    "    new_df.to_csv(\n",
    "        os.path.join(path, \"processed\", \"DART_{}.csv\".format(proj)), index=False\n",
    "    )\n",
    "\n",
    "    # print(new_df.columns)\n",
    "    return new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_dict = {\n",
    "    \"outflow (m3/d)\": \"Average outflow\",\n",
    "    \"inflow (m3/d)\": \"Average inflow\",\n",
    "    \"spill (m3/d)\": \"Average spill\",\n",
    "    \"avg water temperature (C)\": \"Average water temperature\",\n",
    "    \"elevation (m)\": \"Reservoir elevation\",\n",
    "    \"tailwater elevation (m)\": \"Tailwater_elevation\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data for each project\n",
    "proj = dart_stations_metadata[\n",
    "    \"Abbrev\"\n",
    "]  # list of projects https://www.cbr.washington.edu/dart/metadata/river\n",
    "# proj = ['CCIW']\n",
    "# grand_id = [297,  338, '338_tail', 299, '299_tail' ]\n",
    "startDate = \"1999-01-01\"\n",
    "endDate = \"2023-10-30\"\n",
    "\n",
    "# # specify the directory to save the data\n",
    "# data_dir = Path(\n",
    "#     \"/Users/gdarkwah/Library/CloudStorage/OneDrive-UW/01-Research/01-Hydrothermal History/Data/timeseries\"\n",
    "# )\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "os.makedirs(os.path.join(data_dir, \"raw/dart\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(data_dir, \"processed\"), exist_ok=True)\n",
    "\n",
    "# get the data for each project\n",
    "# for p, id in zip(proj, grand_id):\n",
    "for p in proj:\n",
    "    get_data(p, startDate, endDate, data_dir)\n",
    "    parameters = postprocess_data(p, data_dir)\n",
    "\n",
    "    # update the metadata\n",
    "    site_key = \"DART_\" + p.upper()\n",
    "    if site_key not in metadata[\"stations\"].keys():\n",
    "        metadata[\"stations\"][site_key] = {}\n",
    "\n",
    "    metadata[\"stations\"][site_key][\"source\"] = \"CBR DART\"\n",
    "    metadata[\"stations\"][site_key][\"id\"] = p.upper()\n",
    "    metadata[\"stations\"][site_key][\"description\"] = dart_stations_metadata[\n",
    "        dart_stations_metadata[\"Abbrev\"] == p.upper()\n",
    "    ][\"Project Name\"].values[0]\n",
    "\n",
    "    if \"parameters\" not in metadata[\"stations\"][site_key].keys():\n",
    "        metadata[\"stations\"][site_key][\"parameters\"] = {}\n",
    "    for parameter in parameters[1:]:\n",
    "        if parameter not in metadata[\"stations\"][site_key][\"parameters\"].keys():\n",
    "            metadata[\"stations\"][site_key][\"parameters\"][parameter] = parameter_dict[\n",
    "                parameter\n",
    "            ]\n",
    "\n",
    "    metadata[\"stations\"][site_key][\"latitude\"] = dart_stations_metadata[\n",
    "        dart_stations_metadata[\"Abbrev\"] == p.upper()\n",
    "    ][\"Latitude\"].values[0]\n",
    "    metadata[\"stations\"][site_key][\"longitude\"] = dart_stations_metadata[\n",
    "        dart_stations_metadata[\"Abbrev\"] == p.upper()\n",
    "    ][\"Longitude\"].values[0]\n",
    "\n",
    "    metadata[\"stations\"][site_key][\"geometry\"] = {\n",
    "        \"type\": \"Point\",\n",
    "        \"coordinates\": [\n",
    "            dart_stations_metadata[dart_stations_metadata[\"Abbrev\"] == p.upper()][\n",
    "                \"Longitude\"\n",
    "            ].values[0],\n",
    "            dart_stations_metadata[dart_stations_metadata[\"Abbrev\"] == p.upper()][\n",
    "                \"Latitude\"\n",
    "            ].values[0],\n",
    "        ],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add last updated date and last updated by\n",
    "metadata[\"last_updated\"] = pd.Timestamp.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "metadata[\"last_updated_by\"] = \"George Darkwah\"\n",
    "metadata[\"last_updated_by_email\"] = \"gdarkwah@uw.edu\"\n",
    "\n",
    "# save metadata\n",
    "with open(Path(data_dir, \"processed\", \"metadata.json\"), \"w\") as f:\n",
    "    json.dump(metadata, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
