{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "from dataretrieval import nwis\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_dir = Path(\"../../../..\")\n",
    "\n",
    "data_dir = proj_dir / \"Data/InSituTemperature\"\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# load metadata\n",
    "metadata = json.load(Path(data_dir, \"processed\", \"metadata.json\").open(\"r\"))\n",
    "\n",
    "target_parameters = {\n",
    "    \"00010_Maximum\": \"max water temperature (C)\",\n",
    "    \"00010_Minimum\": \"min water temperature (C)\",\n",
    "    \"00010_Mean\": \"avg water temperature (C)\",\n",
    "    \"00060_Mean\": \"avg discharge (cfs)\",\n",
    "}\n",
    "\n",
    "parameter_codes = {\n",
    "    \"max water temperature (C)\": \"Maximum water temperature, degrees Celsius\",\n",
    "    \"min water temperature (C)\": \"Minimum water temperature, degrees Celsius\",\n",
    "    \"avg water temperature (C)\": \"Mean water temperature, degrees Celsius\",\n",
    "    \"avg discharge (cfs)\": \"Discharge, cubic feet per second\",\n",
    "    \"avg discharge (m3/d)\": \"Discharge, cubic meters per day\",\n",
    "}\n",
    "\n",
    "startDt = \"1999-01-01\"\n",
    "endDt = \"2023-10-30\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the shapefile\n",
    "fn = Path(proj_dir, \"Data/GIS/shapefiles/CRBSingle.shp\")\n",
    "gdf = gpd.read_file(fn)\n",
    "# gdf.bounds.values[0]\n",
    "\n",
    "# divide the bounding box into 16 smaller boxes\n",
    "xmin, ymin, xmax, ymax = gdf.bounds.values[0]\n",
    "x = np.linspace(xmin, xmax, 5)\n",
    "y = np.linspace(ymin, ymax, 5)\n",
    "\n",
    "# create a list of lists for the bounding boxes\n",
    "bb = []\n",
    "for i in range(len(x) - 1):\n",
    "    for j in range(len(y) - 1):\n",
    "        bb.append(list(np.array([x[i], y[j], x[i + 1], y[j + 1]]).round(6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the sites for each of the bounding boxes and save them to a dataframe\n",
    "siteList = []\n",
    "for i in range(len(bb)):\n",
    "    try:\n",
    "        siteList.append(nwis.what_sites(bBox=bb[i], startDt=startDt, endDt=endDt, parameterCd='00010')[0])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "siteList_df = pd.concat(siteList, ignore_index=True)\n",
    "\n",
    "filtered_sites = gpd.GeoDataFrame(siteList_df, geometry=gpd.points_from_xy(siteList_df['dec_long_va'], siteList_df['dec_lat_va']), crs='epsg:4326')\n",
    "sites_within_basin = filtered_sites[filtered_sites.within(gdf.geometry[0])]\n",
    "# sites_within_basin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save sites_within_basin to a csv file\n",
    "# sites_within_basin.to_csv(Path(data_dir, \"processed\", \"sites_within_basin2.csv\"), index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the data of filtered sites\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for site in sites_within_basin[\"site_no\"]:\n",
    "# for site in ['14103000']:\n",
    "    # for site in [\"14070615\", \"14070620\", \"14070621\"]:\n",
    "    try:\n",
    "        site_data = nwis.get_record(sites=site, service=\"dv\", start=startDt, end=endDt)\n",
    "        site_data.index.rename(\"date\", inplace=True)\n",
    "        column_dict = {\n",
    "            col: target_parameters[col]\n",
    "            for col in site_data.columns\n",
    "            if col in target_parameters.keys()\n",
    "        }\n",
    "        site_data.rename(\n",
    "            columns=column_dict,\n",
    "            inplace=True,\n",
    "        )\n",
    "        if \"avg discharge (cfs)\" in site_data.columns:\n",
    "            site_data[\"avg discharge (m3/d)\"] = (\n",
    "                site_data[\"avg discharge (cfs)\"] * 0.0283168 * 86400\n",
    "            )\n",
    "            column_dict[\"avg discharge (m3/d)\"] = \"avg discharge (m3/d)\"\n",
    "\n",
    "        if column_dict:\n",
    "            site_data[column_dict.values()].to_csv(\n",
    "                Path(data_dir, \"processed\", f\"USGS_{site}.csv\"), index=True\n",
    "            )\n",
    "\n",
    "            # update metadata\n",
    "            site_key = \"USGS_\" + site\n",
    "            if site_key not in metadata[\"stations\"].keys():\n",
    "                metadata[\"stations\"][site_key] = {}\n",
    "\n",
    "            metadata[\"stations\"][site_key][\"source\"] = \"USGS\"\n",
    "            metadata[\"stations\"][site_key][\"id\"] = site\n",
    "            metadata[\"stations\"][site_key][\"description\"] = sites_within_basin[\n",
    "                sites_within_basin[\"site_no\"] == site\n",
    "            ][\"station_nm\"].values[0]\n",
    "            metadata[\"stations\"][site_key][\"latitude\"] = sites_within_basin[\n",
    "                sites_within_basin[\"site_no\"] == site\n",
    "            ][\"dec_lat_va\"].values[0]\n",
    "            metadata[\"stations\"][site_key][\"longitude\"] = sites_within_basin[\n",
    "                sites_within_basin[\"site_no\"] == site\n",
    "            ][\"dec_long_va\"].values[0]\n",
    "\n",
    "            # TODO: update the parameters instead of overwriting them\n",
    "            if \"parameters\" not in metadata[\"stations\"][site_key].keys():\n",
    "                metadata[\"stations\"][site_key][\"parameters\"] = {}\n",
    "            for key in column_dict.values():\n",
    "                if key not in metadata[\"stations\"][site_key][\"parameters\"].keys():\n",
    "                    metadata[\"stations\"][site_key][\"parameters\"][key] = parameter_codes[key]\n",
    "            \n",
    "            # metadata[\"stations\"][site_key][\"parameters\"] = {\n",
    "            #     key: parameter_codes[key] for key in column_dict.values()\n",
    "            # }\n",
    "            metadata[\"stations\"][site_key][\"geometry\"] = {\n",
    "                \"type\": \"Point\",\n",
    "                \"coordinates\": [\n",
    "                    sites_within_basin[sites_within_basin[\"site_no\"] == site][\n",
    "                        \"dec_long_va\"\n",
    "                    ].values[0],\n",
    "                    sites_within_basin[sites_within_basin[\"site_no\"] == site][\n",
    "                        \"dec_lat_va\"\n",
    "                    ].values[0],\n",
    "                ],\n",
    "            }\n",
    "    except:\n",
    "        raise\n",
    "\n",
    "# add last updated date and last updated by\n",
    "metadata[\"last_updated\"] = pd.Timestamp.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "metadata[\"last_updated_by\"] = \"George Darkwah\"\n",
    "metadata[\"last_updated_by_email\"] = \"gdarkwah@uw.edu\"\n",
    "\n",
    "# save metadata\n",
    "with open(Path(data_dir, \"processed\", \"metadata.json\"), \"w\") as f:\n",
    "    json.dump(metadata, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "4b8c3a16aaf85adb3ca8a1f18e5810b57687b3d06c4b994ba211aab8278e804c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
