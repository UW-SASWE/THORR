{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import sys\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import root_mean_squared_error, mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.model_selection import KFold, ShuffleSplit, RepeatedKFold, train_test_split, ParameterGrid\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import ElasticNetCV, ElasticNet\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "from permetrics.regression import RegressionMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_dir = Path('./')\n",
    "seed = 1993"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_input_data = pd.read_csv(proj_dir / 'ml_inputs_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"NDVI\",\n",
    "    \"LandTempC\",\n",
    "    \"ClimateClass\",\n",
    "    \"DOY\",\n",
    "    # \"WidthMin\",\n",
    "    \"WidthMean\",\n",
    "    # \"WidthMax\",\n",
    "    # \"WaterTempC\",\n",
    "]\n",
    "y_col = \"avg_temp(C)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the data and divide into training and testing\n",
    "ml_input_data = ml_input_data.sample(frac=1).reset_index(drop=True)\n",
    "ml_input_data.dropna(subset=features+[y_col,], inplace=True)\n",
    "\n",
    "# ml_input_data.sort_values(by='Date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the lates date in the input data\n",
    "latest_date = ml_input_data['Date'].max()\n",
    "latest_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"RFR1\"\n",
    "\n",
    "cv_splitter = RepeatedKFold(n_splits=5, \n",
    "                    n_repeats=10, \n",
    "                    random_state=seed\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_set, test_set = train_test_split(ml_input_data, test_size=0.2, random_state=seed)\n",
    "\n",
    "# add the data from the handpicked reaches to the test set\n",
    "dev_set = dev_set[\n",
    "    ~(\n",
    "        (\n",
    "            (dev_set[\"Name\"] == \"Okanogan_River_13\")\n",
    "            | (dev_set[\"Name\"] == \"Columbia_River_96\")\n",
    "            | (dev_set[\"Name\"] == \"Kootenay_River_35\")\n",
    "            | (dev_set[\"Name\"] == \"Willamette_River_20\")\n",
    "        )\n",
    "        & (dev_set[\"Date\"] > \"2020-01-01\")\n",
    "    )\n",
    "].copy()\n",
    "\n",
    "test_set = pd.concat(\n",
    "    [test_set, dev_set[\n",
    "        (\n",
    "            (dev_set[\"Name\"] == \"Okanogan_River_13\")\n",
    "            | (dev_set[\"Name\"] == \"Columbia_River_96\")\n",
    "            | (dev_set[\"Name\"] == \"Kootenay_River_35\")\n",
    "            | (dev_set[\"Name\"] == \"Willamette_River_20\")\n",
    "        )\n",
    "        & (dev_set[\"Date\"] > \"2020-01-01\")\n",
    "    ]],\n",
    "    \n",
    ").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparmeters = {\n",
    "    \"n_estimators\": [10, 20, 30, 40, 50, 75, 100, 125, 150, 175, 200, 250, 300, 350, 400, 450, 500, 1000],\n",
    "}\n",
    "hyperparmeters = {\n",
    "    \"n_estimators\": [200,],\n",
    "}\n",
    "\n",
    "list_metrics = [\"RMSE\", \"MAE\", \"NSE\", \"R2\", \"KGE\", \"MSE\"]\n",
    "\n",
    "dev_results = pd.DataFrame(columns=[\"parameters\", \"combination\", \"fold\"] + list_metrics)\n",
    "\n",
    "test_results = pd.DataFrame(columns=[\"parameters\", \"combination\"] + list_metrics)\n",
    "\n",
    "# for i, l1_ratio in enumerate(hyperparmeters['l1_ratio']):\n",
    "for i, params in enumerate(ParameterGrid(hyperparmeters)):\n",
    "    n_estimators = params[\"n_estimators\"]\n",
    "    for j, (train_idx, val_idx) in enumerate(cv_splitter.split(dev_set)):\n",
    "        train_set = dev_set.iloc[train_idx].copy()\n",
    "        val_set = dev_set.iloc[val_idx].copy()\n",
    "\n",
    "        X_train = train_set[features]\n",
    "        y_train = train_set[y_col]\n",
    "\n",
    "        X_val = val_set[features]\n",
    "        y_val = val_set[y_col]\n",
    "\n",
    "        model = RandomForestRegressor(n_estimators=n_estimators, random_state=seed)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        val_set[\"y_pred\"] = y_pred\n",
    "\n",
    "        # mse = mean_squared_error(y_val, y_pred)\n",
    "        # rmse = np.sqrt(mse)\n",
    "        # r2 = r2_score(y_val, y_pred)\n",
    "        # # nse = 1 - mse / np.var(y_val)\n",
    "        # mae = np.mean(np.abs(y_val - y_pred))\n",
    "\n",
    "        evaluator = RegressionMetric(list(y_val), list(y_pred))\n",
    "\n",
    "        dev_results = pd.concat(\n",
    "            [\n",
    "                dev_results,\n",
    "                pd.DataFrame(\n",
    "                    [\n",
    "                        [params, i, j]\n",
    "                        + list(\n",
    "                            evaluator.get_metrics_by_list_names(list_metrics).values()\n",
    "                        )\n",
    "                    ],\n",
    "                    columns=[\"parameters\", \"combination\", \"fold\"] + list_metrics,\n",
    "                    index=[j],\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    X_dev = dev_set[features]\n",
    "    y_dev = dev_set[y_col]\n",
    "\n",
    "    X_test = test_set[features]\n",
    "    y_test = test_set[y_col]\n",
    "\n",
    "    model = RandomForestRegressor(n_estimators=n_estimators, random_state=seed)\n",
    "    model.fit(X_dev, y_dev)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    test_set[\"y_pred\"] = y_pred\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    # nse = 1 - mse / np.var(y_val)\n",
    "    mae = np.mean(np.abs(y_test - y_pred))\n",
    "\n",
    "    evaluator = RegressionMetric(list(y_test), list(y_pred))\n",
    "\n",
    "    test_results = pd.concat(\n",
    "        [\n",
    "            test_results,\n",
    "            pd.DataFrame(\n",
    "                [\n",
    "                    [params, i]\n",
    "                    + list(evaluator.get_metrics_by_list_names(list_metrics).values())\n",
    "                ],\n",
    "                columns=[\"parameters\", \"combination\"] + list_metrics,\n",
    "                index=[i],\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "test_results['n_estimators'] = test_results['parameters'].apply(lambda x: x['n_estimators'])\n",
    "dev_results['n_estimators'] = dev_results['parameters'].apply(lambda x: x['n_estimators'])\n",
    "\n",
    "dev_results.to_csv(\n",
    "    f\"{model_name}_dev_results.csv\", index=False\n",
    ")\n",
    "test_results.to_csv(\n",
    "    f\"{model_name}_test_results.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results[\"delta_MSE\"] = np.abs(test_results[\"MSE\"] - test_results[\"MSE\"].shift(1))\n",
    "\n",
    "# find the set of hyperparmeters with a patience of 5 for delta MSE at 0.005\n",
    "patience = 5\n",
    "delta = 0.005\n",
    "\n",
    "test_results[\"patience\"] = test_results[\"delta_MSE\"].apply(lambda x: 1 if x < delta else 0)\n",
    "test_results[\"patience\"] = test_results[\"patience\"] + test_results[\"patience\"].shift(-1) + test_results[\"patience\"].shift(-2) + test_results[\"patience\"].shift(-3) + test_results[\"patience\"].shift(-4)\n",
    "\n",
    "# get the first hyperparmeters with the patience of 5\n",
    "best_hyperparameters = test_results[test_results[\"patience\"] == patience].iloc[0][\"parameters\"]\n",
    "# save the best hyperparmeters\n",
    "with open(f\"{model_name}_params.json\", \"w\") as f:\n",
    "            json.dump(best_hyperparameters, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_model = RandomForestRegressor(n_estimators=best_hyperparameters[\"n_estimators\"], random_state=seed)\n",
    "final_model = RandomForestRegressor(n_estimators=100, random_state=seed)\n",
    "final_model.fit(dev_set[features], dev_set[y_col])\n",
    "\n",
    "test_set[\"y_pred\"] = final_model.predict(test_set[features])\n",
    "test_set.to_csv(f\"{model_name}_test_set.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot and mean line of the dev results for each parameter\n",
    "fig, ax = plt.subplots(1,2, figsize=(12, 6))\n",
    "dev_results.boxplot(column='MSE', by='n_estimators', ax=ax[1])\n",
    "dev_results.groupby('n_estimators').mean(numeric_only=True).plot(y='MSE', ax=ax[0], color='black', marker='o')\n",
    "ax[0].axvline(x=best_hyperparameters['n_estimators'], color='red', linestyle='--', label='No. of Trees = 100')\n",
    "ax[0].legend()\n",
    "# ax[0].set_title('Mean MSE for different number of estimators')\n",
    "ax[0].set_title('a)')\n",
    "# ax[1].set_title('Distribution of MSE for different number of estimators')\n",
    "ax[1].set_title('b)')\n",
    "ax[0].set_xlabel('Number of Trees')\n",
    "ax[0].set_ylabel('Mean Squared Error')\n",
    "ax[1].set_xlabel('Number of Trees')\n",
    "ax[1].set_ylabel('Mean Squared Error')\n",
    "fig.suptitle('')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot of the test results\n",
    "fig, ax = plt.subplots(1,1, figsize=(5, 5))\n",
    "test_set.plot.scatter(x='avg_temp(C)', y='y_pred', ax=ax, s=.75)\n",
    "ax.plot([0, 30], [0, 30], color='k', linestyle='--')\n",
    "ax.set_xlabel('In-situ Water Temperature (C)')\n",
    "ax.set_ylabel('Estimated Water Temperature (C)')\n",
    "ax.set_title('Random Forest Regression')\n",
    "\n",
    "mae, mse, rmse, r2, nse, kge = test_results[test_results[\"patience\"] == patience].iloc[0][['MAE', 'MSE', 'RMSE', 'R2', 'NSE', 'KGE']]\n",
    "\n",
    "ax.annotate(f'MAE: {mae:.2f}', xy=(0.05, 0.9), xycoords='axes fraction')\n",
    "ax.annotate(f'MSE: {mse:.2f}', xy=(0.05, 0.85), xycoords='axes fraction')\n",
    "ax.annotate(f'RMSE: {rmse:.2f}', xy=(0.05, 0.8), xycoords='axes fraction')\n",
    "ax.annotate(f'R2: {r2:.2f}', xy=(0.05, 0.75), xycoords='axes fraction')\n",
    "ax.annotate(f'NSE: {nse:.2f}', xy=(0.05, 0.7), xycoords='axes fraction')\n",
    "ax.annotate(f'KGE: {kge:.2f}', xy=(0.05, 0.65), xycoords='axes fraction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model with the best hyperparameters on all the data and save it\n",
    "final_model = RandomForestRegressor(n_estimators=best_hyperparameters[\"n_estimators\"], random_state=seed)\n",
    "\n",
    "X = ml_input_data[features]\n",
    "y = ml_input_data[y_col]\n",
    "\n",
    "final_model.fit(X, y)\n",
    "\n",
    "dump(final_model, f\"{model_name}.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydrothermal-history",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
