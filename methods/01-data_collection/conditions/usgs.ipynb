{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataretrieval import nwis\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_dir = Path(\"../../../\")\n",
    "\n",
    "data_dir = proj_dir / \"Data/insitu/conditions\"\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# load metadata\n",
    "stations_metadata_path = Path(proj_dir, \"Data/insitu/metadata/stations.csv\")\n",
    "stations_attributes_path = Path(proj_dir, \"Data/insitu/metadata/dictionaries/stations_attributes.csv\")\n",
    "\n",
    "stations_attributes = pd.read_csv(stations_attributes_path)\n",
    "\n",
    "if not os.path.exists(stations_metadata_path):\n",
    "    stations_metadata = pd.DataFrame(columns=stations_attributes['Attribute_name'])\n",
    "    stations_metadata.to_csv(stations_metadata_path, index=False)\n",
    "\n",
    "stations_metadata = pd.read_csv(stations_metadata_path)\n",
    "\n",
    "target_parameters = {\n",
    "    \"00010_Maximum\": \"max_temp(C)\",\n",
    "    \"00010_Minimum\": \"min_temp(C)\",\n",
    "    \"00010_Mean\": \"avg_temp(C)\",\n",
    "    \"00060_Mean\": \"avg discharge (cfs)\",\n",
    "}\n",
    "\n",
    "parameter_codes = {\n",
    "    \"max water temperature (C)\": \"Maximum water temperature, degrees Celsius\",\n",
    "    \"min water temperature (C)\": \"Minimum water temperature, degrees Celsius\",\n",
    "    \"avg water temperature (C)\": \"Mean water temperature, degrees Celsius\",\n",
    "    \"avg discharge (cfs)\": \"Discharge, cubic feet per second\",\n",
    "    \"avg discharge (m3/d)\": \"Discharge, cubic meters per day\",\n",
    "}\n",
    "\n",
    "startDt = \"1982-08-01\"\n",
    "endDt = \"2024-02-26\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the basin vector data\n",
    "basin_gdf = gpd.read_file(proj_dir / \"data/gis/geopackages/columbia_river_basin.gpkg\", layer=\"Basins\")\n",
    "\n",
    "# divide the bounding box into 16 smaller boxes\n",
    "xmin, ymin, xmax, ymax = basin_gdf.bounds.values[0]\n",
    "x = np.linspace(xmin, xmax, 5)\n",
    "y = np.linspace(ymin, ymax, 5)\n",
    "\n",
    "# create a list of lists for the bounding boxes\n",
    "bb = []\n",
    "for i in range(len(x) - 1):\n",
    "    for j in range(len(y) - 1):\n",
    "        bb.append(list(np.array([x[i], y[j], x[i + 1], y[j + 1]]).round(6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the sites for each of the bounding boxes and save them to a dataframe\n",
    "siteList = []\n",
    "for i in range(len(bb)):\n",
    "    try:\n",
    "        siteList.append(nwis.what_sites(bBox=bb[i], startDt=startDt, endDt=endDt, parameterCd='00010')[0])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siteList_df = pd.concat(siteList, ignore_index=True)\n",
    "\n",
    "filtered_sites = gpd.GeoDataFrame(siteList_df, geometry=gpd.points_from_xy(siteList_df['dec_long_va'], siteList_df['dec_lat_va']), crs='epsg:4326')\n",
    "sites_within_basin = filtered_sites[filtered_sites.within(basin_gdf.geometry[0])]\n",
    "# sites_within_basin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save sites_within_basin to a csv file\n",
    "# sites_within_basin.to_csv(Path(data_dir, \"processed\", \"sites_within_basin2.csv\"), index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the data of filtered sites\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for site in sites_within_basin[\"site_no\"]:\n",
    "for site in ['12301933']:\n",
    "    # for site in [\"14070615\", \"14070620\", \"14070621\"]:\n",
    "    try:\n",
    "        site_data = nwis.get_record(sites=site, service=\"dv\", start=startDt, end=endDt)\n",
    "        site_data.index.rename(\"date\", inplace=True)\n",
    "        column_dict = {\n",
    "            col: target_parameters[col]\n",
    "            for col in site_data.columns\n",
    "            if col in target_parameters.keys()\n",
    "        }\n",
    "        site_data.rename(\n",
    "            columns=column_dict,\n",
    "            inplace=True,\n",
    "        )\n",
    "        if \"avg discharge (cfs)\" in site_data.columns:\n",
    "            site_data[\"outflow(m3/d)\"] = (\n",
    "                site_data[\"avg discharge (cfs)\"] * 0.0283168 * 86400\n",
    "            )\n",
    "            column_dict[\"outflow(m3/d)\"] = \"outflow(m3/d)\"\n",
    "\n",
    "        if column_dict:\n",
    "            site_data[column_dict.values()].to_csv(\n",
    "                Path(data_dir, \"processed\", f\"USGS_{site}.csv\"), index=True\n",
    "            )\n",
    "\n",
    "            # update metadata\n",
    "            station_ID = \"USGS_\" + site.upper()\n",
    "\n",
    "            if station_ID not in stations_metadata[\"station_ID\"].values:\n",
    "                stations_metadata = pd.concat(\n",
    "                    [\n",
    "                        stations_metadata,\n",
    "                        pd.DataFrame(\n",
    "                            {\n",
    "                                \"station_ID\": [station_ID],\n",
    "                                \"id_at_source\": [site.upper()],\n",
    "                                \"available_data\": [\"{}\"],\n",
    "                                \"source_URL\": ['{\"url\" : []}'],\n",
    "                                \"description\": [\n",
    "                                    sites_within_basin[\n",
    "                                        sites_within_basin[\"site_no\"] == site\n",
    "                                    ][\"station_nm\"].values[0]\n",
    "                                ],\n",
    "                                \"latitude\": [\n",
    "                                    sites_within_basin[\n",
    "                                        sites_within_basin[\"site_no\"] == site\n",
    "                                    ][\"dec_lat_va\"].values[0]\n",
    "                                ],\n",
    "                                \"longitude\": [\n",
    "                                    sites_within_basin[\n",
    "                                        sites_within_basin[\"site_no\"] == site\n",
    "                                    ][\"dec_long_va\"].values[0]\n",
    "                                ],\n",
    "                                \"site_params\": [\"{}\"],\n",
    "                            }\n",
    "                        ),\n",
    "                    ],\n",
    "                    ignore_index=True,\n",
    "                )\n",
    "\n",
    "            # update source url\n",
    "            source_url = json.loads(\n",
    "                stations_metadata.loc[\n",
    "                    stations_metadata[\"station_ID\"] == station_ID, \"source_URL\"\n",
    "                ].values[0]\n",
    "            )\n",
    "\n",
    "            if (\n",
    "                f\"https://waterdata.usgs.gov/monitoring-location/{site}\"\n",
    "                not in source_url[\"url\"]\n",
    "            ):\n",
    "                source_url[\"url\"].append(\n",
    "                    f\"https://waterdata.usgs.gov/monitoring-location/{site}\"\n",
    "                )\n",
    "                stations_metadata.loc[\n",
    "                    stations_metadata[\"station_ID\"] == station_ID, \"source_URL\"\n",
    "                ] = json.dumps(source_url)\n",
    "\n",
    "            # update the available data\n",
    "            availble_data = stations_metadata.loc[\n",
    "                stations_metadata[\"station_ID\"] == station_ID, \"available_data\"\n",
    "            ].values[0]\n",
    "            availble_data = json.loads(availble_data)\n",
    "\n",
    "            # check if there is \"conditions\"  in the available data\n",
    "            if \"conditions\" not in availble_data.values():\n",
    "                availble_data[\"conditions\"] = []\n",
    "            # add the parameters to the available data\n",
    "            # print(parameters[1:])\n",
    "            for param in column_dict.values():\n",
    "                if param not in availble_data[\"conditions\"]:\n",
    "                    availble_data[\"conditions\"].append(param)\n",
    "\n",
    "            # update the metadata\n",
    "            stations_metadata.loc[\n",
    "                stations_metadata[\"station_ID\"] == station_ID, \"available_data\"\n",
    "            ] = json.dumps(availble_data)\n",
    "\n",
    "            # save the metadata\n",
    "            stations_metadata.to_csv(stations_metadata_path, index=False)\n",
    "    except:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add last updated date and last updated by\n",
    "metadata_status = {\n",
    "    \"last_updated\": pd.Timestamp.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"update_message\": \"Updated the metadata to for USGS stations\",\n",
    "    \"last_updated_by\": \"George Darkwah\",\n",
    "    \"last_updated_by_email\": \"gdarkwah@uw.edu\",\n",
    "}\n",
    "\n",
    "# save metadata\n",
    "with open(Path(proj_dir, \"Data/insitu/metadata/metadata_status.csv\"), \"w\") as f:\n",
    "    json.dump(metadata_status, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "4b8c3a16aaf85adb3ca8a1f18e5810b57687b3d06c4b994ba211aab8278e804c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
