{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import sys\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import root_mean_squared_error, mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.model_selection import KFold, ShuffleSplit, RepeatedKFold, train_test_split, ParameterGrid\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import ElasticNetCV, ElasticNet\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "from permetrics.regression import RegressionMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_dir = Path('../../..')\n",
    "seed = 1993"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_input_data = pd.read_csv(proj_dir / 'methods/04-ml_development/input_data/ml_input_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the data and divide into training and testing\n",
    "ml_input_data = ml_input_data.sample(frac=1).reset_index(drop=True)\n",
    "ml_input_data.dropna(subset=['LandTempC', 'NDVI'], inplace=True)\n",
    "\n",
    "# ml_input_data.sort_values(by='Date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"NDVI\",\n",
    "    \"LandTempC\",\n",
    "    \"ClimateClass\",\n",
    "    \"DOY\",\n",
    "    # \"WidthMin\",\n",
    "    \"WidthMean\",\n",
    "    # \"WidthMax\",\n",
    "    # \"WaterTempC\",\n",
    "]\n",
    "y_col = \"avg_temp(C)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"LR1\"\n",
    "\n",
    "cv_splitter = RepeatedKFold(n_splits=5, \n",
    "                    n_repeats=10, \n",
    "                    random_state=seed\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_set, test_set = train_test_split(ml_input_data, test_size=0.2, random_state=seed)\n",
    "\n",
    "# add the data from the handpicked reaches to the test set\n",
    "dev_set = dev_set[\n",
    "    ~(\n",
    "        (\n",
    "            (dev_set[\"Name\"] == \"Okanogan_River_13\")\n",
    "            | (dev_set[\"Name\"] == \"Columbia_River_96\")\n",
    "            | (dev_set[\"Name\"] == \"Kootenay_River_35\")\n",
    "            | (dev_set[\"Name\"] == \"Willamette_River_20\")\n",
    "        )\n",
    "        & (dev_set[\"Date\"] > \"2020-01-01\")\n",
    "    )\n",
    "].copy()\n",
    "\n",
    "test_set = pd.concat(\n",
    "    [test_set, dev_set[\n",
    "        (\n",
    "            (dev_set[\"Name\"] == \"Okanogan_River_13\")\n",
    "            | (dev_set[\"Name\"] == \"Columbia_River_96\")\n",
    "            | (dev_set[\"Name\"] == \"Kootenay_River_35\")\n",
    "            | (dev_set[\"Name\"] == \"Willamette_River_20\")\n",
    "        )\n",
    "        & (dev_set[\"Date\"] > \"2020-01-01\")\n",
    "    ]],\n",
    "    \n",
    ").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparmeters = {\n",
    "    \"l1_ratio\": [0.1, 0.3, 0.5, 0.6, 0.7, 0.8, 0.85, 0.9, 0.925, 0.95, 0.975, 1],\n",
    "    \"alpha\": np.arange(0.01, 1, 0.01),\n",
    "    # 'alpha': [0.01],\n",
    "}\n",
    "\n",
    "list_metrics = [\"RMSE\", \"MAE\", \"NSE\", \"R2\", \"KGE\", \"MSE\"]\n",
    "\n",
    "dev_results = pd.DataFrame(columns=[\"parameters\", \"combination\", \"fold\"] + list_metrics)\n",
    "\n",
    "test_results = pd.DataFrame(columns=[\"parameters\", \"combination\"] + list_metrics)\n",
    "\n",
    "# for i, l1_ratio in enumerate(hyperparmeters['l1_ratio']):\n",
    "for i, params in enumerate(ParameterGrid(hyperparmeters)):\n",
    "    l1_ratio = params[\"l1_ratio\"]\n",
    "    alpha = params[\"alpha\"]\n",
    "    for j, (train_idx, val_idx) in enumerate(cv_splitter.split(dev_set)):\n",
    "        train_set = dev_set.iloc[train_idx].copy()\n",
    "        val_set = dev_set.iloc[val_idx].copy()\n",
    "\n",
    "        X_train = train_set[features]\n",
    "        y_train = train_set[y_col]\n",
    "\n",
    "        X_val = val_set[features]\n",
    "        y_val = val_set[y_col]\n",
    "\n",
    "        model = ElasticNet(l1_ratio=l1_ratio, random_state=seed, alpha=alpha)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        val_set[\"y_pred\"] = y_pred\n",
    "\n",
    "        # mse = mean_squared_error(y_val, y_pred)\n",
    "        # rmse = np.sqrt(mse)\n",
    "        # r2 = r2_score(y_val, y_pred)\n",
    "        # # nse = 1 - mse / np.var(y_val)\n",
    "        # mae = np.mean(np.abs(y_val - y_pred))\n",
    "\n",
    "        evaluator = RegressionMetric(list(y_val), list(y_pred))\n",
    "\n",
    "        dev_results = pd.concat(\n",
    "            [\n",
    "                dev_results,\n",
    "                pd.DataFrame(\n",
    "                    [\n",
    "                        [params, i, j]\n",
    "                        + list(\n",
    "                            evaluator.get_metrics_by_list_names(list_metrics).values()\n",
    "                        )\n",
    "                    ],\n",
    "                    columns=[\"parameters\", \"combination\", \"fold\"] + list_metrics,\n",
    "                    index=[j],\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    X_dev = dev_set[features]\n",
    "    y_dev = dev_set[y_col]\n",
    "\n",
    "    X_test = test_set[features]\n",
    "    y_test = test_set[y_col]\n",
    "\n",
    "    model = ElasticNet(l1_ratio=l1_ratio, random_state=seed, alpha=alpha)\n",
    "    model.fit(X_dev, y_dev)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    test_set[\"y_pred\"] = y_pred\n",
    "\n",
    "    # mse = mean_squared_error(y_test, y_pred)\n",
    "    # rmse = np.sqrt(mse)\n",
    "    # r2 = r2_score(y_test, y_pred)\n",
    "    # # nse = 1 - mse / np.var(y_val)\n",
    "    # mae = np.mean(np.abs(y_test - y_pred))\n",
    "\n",
    "    evaluator = RegressionMetric(list(y_test), list(y_pred))\n",
    "\n",
    "    test_results = pd.concat(\n",
    "        [\n",
    "            test_results,\n",
    "            pd.DataFrame(\n",
    "                [\n",
    "                    [params, i]\n",
    "                    + list(evaluator.get_metrics_by_list_names(list_metrics).values())\n",
    "                ],\n",
    "                columns=[\"parameters\", \"combination\"] + list_metrics,\n",
    "                index=[i],\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # if mse is the minimum in the test results, save the model, parameters and test results\n",
    "    if evaluator.MSE() == test_results.MSE.min():\n",
    "        dump(model, f\"{model_name}_model.joblib\")\n",
    "        with open(f\"{model_name}_params.json\", \"w\") as f:\n",
    "            json.dump(params, f)\n",
    "\n",
    "        test_set.to_csv(f\"{model_name}_test_set.csv\", index=False)\n",
    "\n",
    "test_results['l1_ratio'] = test_results['parameters'].apply(lambda x: x['l1_ratio'])\n",
    "test_results['alpha'] = test_results['parameters'].apply(lambda x: x['alpha'])\n",
    "dev_results['l1_ratio'] = dev_results['parameters'].apply(lambda x: x['l1_ratio'])\n",
    "dev_results['alpha'] = dev_results['parameters'].apply(lambda x: x['alpha'])\n",
    "\n",
    "dev_results.to_csv(f\"{model_name}_dev_results.csv\", index=False)\n",
    "test_results.to_csv(f\"{model_name}_test_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results['parameters'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot of the test results\n",
    "fig, ax = plt.subplots(1,1, figsize=(5, 5))\n",
    "test_set.plot.scatter(x='avg_temp(C)', y='y_pred', ax=ax, s=.75)\n",
    "ax.plot([0, 30], [0, 30], color='k', linestyle='--')\n",
    "ax.set_xlabel('In-situ Water Temperature (C)')\n",
    "ax.set_ylabel('Estimated Water Temperature (C)')\n",
    "ax.set_title('Linear Regression')\n",
    "# ax.set_title('ElasticNet Linear Regression')\n",
    "\n",
    "mae, mse, rmse, r2, nse, kge = test_results[test_results[\"MSE\"] == test_results.MSE.min()].iloc[0][['MAE', 'MSE', 'RMSE', 'R2', 'NSE', 'KGE']]\n",
    "\n",
    "ax.annotate(f'MAE: {mae:.2f}', xy=(0.05, 0.9), xycoords='axes fraction')\n",
    "ax.annotate(f'MSE: {mse:.2f}', xy=(0.05, 0.85), xycoords='axes fraction')\n",
    "ax.annotate(f'RMSE: {rmse:.2f}', xy=(0.05, 0.8), xycoords='axes fraction')\n",
    "ax.annotate(f'R2: {r2:.2f}', xy=(0.05, 0.75), xycoords='axes fraction')\n",
    "ax.annotate(f'NSE: {nse:.2f}', xy=(0.05, 0.7), xycoords='axes fraction')\n",
    "ax.annotate(f'KGE: {kge:.2f}', xy=(0.05, 0.65), xycoords='axes fraction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model with the best hyperparameters on all the data and save it\n",
    "best_params = test_results.loc[test_results.MSE.idxmin(), \"parameters\"]\n",
    "l1_ratio = best_params[\"l1_ratio\"]\n",
    "alpha = best_params[\"alpha\"]\n",
    "\n",
    "X = ml_input_data[features]\n",
    "y = ml_input_data[y_col]\n",
    "\n",
    "model = ElasticNet(l1_ratio=l1_ratio, random_state=seed, alpha=alpha)\n",
    "model.fit(X, y)\n",
    "\n",
    "dump(model, f\"{model_name}_model.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydrothermal-history",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
